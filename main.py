import os
import json
import time
import requests
import base64
from datetime import datetime
import google.generativeai as genai
from dotenv import load_dotenv
from tqdm import tqdm
from pypdf import PdfReader, PdfWriter  # For PDF page count
from pdf2image import convert_from_path  # For converting PDF to images
from io import BytesIO

# Load environment variables
load_dotenv()

class GSEBPDFProcessor:
    def __init__(self):
        # Initialize Google Cloud Vision API key
        self.vision_api_key = os.getenv('GOOGLE_CLOUD_VISION_API_KEY')
        if not self.vision_api_key:
            raise ValueError("GOOGLE_CLOUD_VISION_API_KEY not found in environment variables")
        
        # Initialize Gemini
        gemini_api_key = os.getenv('GEMINI_API_KEY')
        if not gemini_api_key:
            raise ValueError("GEMINI_API_KEY not found in environment variables")
            
        genai.configure(api_key=gemini_api_key)
        self.gemini_model = genai.GenerativeModel('gemini-2.0-flash')
        
        # API call counters
        self.api_calls = {
            "vision_api": 0,
            "gemini_api": 0,
            "total_tokens_used": 0,
            "start_time": datetime.now()
        }
        
        # Class 10 Maths Gujarati specific prompts
        self.prompts = self._load_subject_prompts()
        
        print("ğŸ”§ Initialized GSEB PDF Processor")
        print(f"ğŸ”‘ Vision API Key: {'âœ… Loaded' if self.vision_api_key else 'âŒ Missing'}")
        print(f"ğŸ”‘ Gemini API Key: {'âœ… Loaded' if gemini_api_key else 'âŒ Missing'}")
        print("ğŸ“Š API Call Counter: Initialized")
        
    def _load_subject_prompts(self):
        """Load Class 10 Mathematics Gujarati specific prompts"""
        return {
            "page_summarization": """
            àª¤àª®à«‡ àªµàª°à«àª— 10àª¨àª¾ àª—àª£àª¿àª¤ àªµàª¿àª·àª¯àª¨à«àª‚ àªªà«àª¸à«àª¤àª• (àª—à«àªœàª°àª¾àª¤à«€ àª®àª¾àª§à«àª¯àª®) àª¨à«àª‚ àªµàª¿àª¶à«àª²à«‡àª·àª£ àª•àª°à«‹ àª›à«‹.
            àª† àªªàª¾àª¨àª¾àª¨à«€ àª¸àª¾àª®àª—à«àª°à«€àª¨à«‹ àª¸àª¾àª°àª¾àª‚àª¶ àª—à«àªœàª°àª¾àª¤à«€àª®àª¾àª‚ àª†àªªà«‹, àªœà«‡àª®àª¾àª‚ àª¨à«€àªšà«‡àª¨à«€ àª¬àª¾àª¬àª¤à«‹ àª¸àª®àª¾àªµà«‡àª¶ àª•àª°à«‹:
            
            - àª®à«àª–à«àª¯ àª—àª£àª¿àª¤à«€àª¯ àª¸àª‚àª•àª²à«àªªàª¨àª¾àª“ (Key mathematical concepts)
            - àª¸à«‚àª¤à«àª°à«‹ àª…àª¨à«‡ àª¨àª¿àª¯àª®à«‹ (Formulas and rules)
            - àª‰àª¦àª¾àª¹àª°àª£à«‹ (Examples) - àªœà«‹ àª•à«‹àªˆ àª¹à«‹àª¯ àª¤à«‹
            - àª•àª¸à«‹àªŸà«€àª“ (Exercises) - àªœà«‹ àª•à«‹àªˆ àª¹à«‹àª¯ àª¤à«‹  
            - àªšàª¿àª¤à«àª°à«‹/àª†àª•à«ƒàª¤àª¿àª“ (Diagrams) - àªœà«‹ àª•à«‹àªˆ àª¹à«‹àª¯ àª¤à«‹
            
            àªªàª¾àª¨àª¾àª¨à«€ àª¸àª¾àª®àª—à«àª°à«€: {page_text}
            
            àªšàª¿àª¤à«àª°à«‹àª¨à«€ àª®àª¾àª¹àª¿àª¤à«€: {image_descriptions}
            
            àª—à«àªœàª°àª¾àª¤à«€àª®àª¾àª‚ àª¸àª¾àª°àª¾àª‚àª¶ àª†àªªà«‹:
            """,
            "chapter_analysis": """
            àª¤àª®à«‡ àªµàª°à«àª— 10àª¨àª¾ àª—àª£àª¿àª¤ àª…àª§à«àª¯àª¾àª¯àª¨à«àª‚ àªµàª¿àª¶à«àª²à«‡àª·àª£ àª•àª°à«‹ àª›à«‹. àª¤àª®àª¾àª® àªªàª¾àª¨àª¾àª“àª¨àª¾ àª¸àª¾àª°àª¾àª‚àª¶àª¨àª¾ àª†àª§àª¾àª°à«‡ àª¨à«€àªšà«‡àª¨à«€ àª®àª¾àª¹àª¿àª¤à«€ àª†àªªà«‹:
            
            àªªàª¾àª¨àª¾àª“àª¨àª¾ àª¸àª¾àª°àª¾àª‚àª¶: {page_summaries}
            
            àª•à«ƒàªªàª¾ àª•àª°à«€àª¨à«‡ àª†àªªà«‹:
            
            **àª…àª§à«àª¯àª¾àª¯àª¨à«‹ àª¸àª‚àªªà«‚àª°à«àª£ àª¸àª¾àª°àª¾àª‚àª¶:**
            [àª¸àª‚àªªà«‚àª°à«àª£ àª…àª§à«àª¯àª¾àª¯àª¨à«‹ àª¸àª¾àª°àª¾àª‚àª¶]
            
            **àª®à«àª–à«àª¯ àªµàª¿àª·àª¯à«‹àª¨à«€ àª¯àª¾àª¦à«€:**
            1. [àªµàª¿àª·àª¯ 1]
            2. [àªµàª¿àª·àª¯ 2]
            3. [àªµàª¿àª·àª¯ 3]
            
            **àª¶à«€àª–àªµàª¾àª¨àª¾ àªªàª°àª¿àª£àª¾àª®à«‹:**
            - [àªªàª°àª¿àª£àª¾àª® 1]
            - [àªªàª°àª¿àª£àª¾àª® 2]
            """,
            "topic_assignment": """
            àª† àªªàª¾àª¨àª¾àª¨à«€ àª¸àª¾àª®àª—à«àª°à«€ àª…àª¨à«‡ àªµàª¿àª·àª¯à«‹àª¨à«€ àª¯àª¾àª¦à«€àª¨àª¾ àª†àª§àª¾àª°à«‡, àª† àªªàª¾àª¨àª¾àª¨à«‡ àª¸àª‚àª¬àª‚àª§àª¿àª¤ àªµàª¿àª·àª¯à«‹àª¨àª¾ àª¨àª‚àª¬àª° àª†àªªà«‹.
            
            àª¨àª¿àª¯àª®à«‹:
            - àªàª• àªªàª¾àª¨àª¾àª®àª¾àª‚ àª¬àª¹à«àªµàª¿àª§ àªµàª¿àª·àª¯à«‹ àª¹à«‹àªˆ àª¶àª•à«‡
            - àªàª• àªœ àªµàª¿àª·àª¯ àª¬à«‡ àªµàª–àª¤ àª¨ àª†àªµàªµà«‹ àªœà«‹àªˆàª
            - àª«àª•à«àª¤ àª¸à«Œàª¥à«€ àª¸àª‚àª¬àª‚àª§àª¿àª¤ àªµàª¿àª·àª¯à«‹ àªªàª¸àª‚àª¦ àª•àª°à«‹
            
            àªªàª¾àª¨àª¾àª¨à«€ àª¸àª¾àª®àª—à«àª°à«€: {page_text}
            
            àª‰àªªàª²àª¬à«àª§ àªµàª¿àª·àª¯à«‹:
            {topics_list}
            
            àª«àª•à«àª¤ àªµàª¿àª·àª¯ àª¨àª‚àª¬àª°à«‹ àª†àªªà«‹ (comma separated):
            """,
            "image_description": """
            àª† àª—àª£àª¿àª¤àª¨àª¾ àªšàª¿àª¤à«àª°àª¨à«àª‚ àª¶à«ˆàª•à«àª·àª£àª¿àª• àªµàª°à«àª£àª¨ àª—à«àªœàª°àª¾àª¤à«€àª®àª¾àª‚ àª†àªªà«‹:
            
            àªšàª¿àª¤à«àª°àª®àª¾àª‚ àªœà«‡ àª¦à«‡àª–àª¾àª¯ àª›à«‡: {image_content}
            
            àª¸àª‚àª¦àª°à«àª­: àªµàª°à«àª— 10 àª—àª£àª¿àª¤ - {context}
            
            àª—à«àªœàª°àª¾àª¤à«€àª®àª¾àª‚ àª¶à«ˆàª•à«àª·àª£àª¿àª• àªµàª°à«àª£àª¨ àª†àªªà«‹ (àª¶à«àª‚ àª¦à«‡àª–àª¾àª¯ àª›à«‡, àª•à«‡àªµàª¾ àª‰àªªàª¯à«‹àª— àª®àª¾àªŸà«‡ àª›à«‡):
            """
        }
    

    def extract_pdf_with_images(self, pdf_path):
        """Extract text and images from PDF with enhanced detection capabilities"""
        print("\n" + "="*50)
        print("ğŸ“„ STEP 1: ENHANCED PDF EXTRACTION WITH IMAGES (PAGE BY PAGE)")
        print("="*50)
        print(f"ğŸ“„ Processing file: {os.path.basename(pdf_path)}")
        print(f"ğŸ“Š API Call Status - Vision: {self.api_calls['vision_api']}, Gemini: {self.api_calls['gemini_api']}")
        
        start_time = time.time()
        
        # Convert PDF to images using pdf2image
        try:
            images = convert_from_path(pdf_path, dpi=300, fmt='png')
            print(f"ğŸ“„ Converted {len(images)} pages to images")
        except Exception as e:
            print(f"âŒ Failed to convert PDF to images: {str(e)[:100]}...")
            return []
        
        pages_data = []
        
        for page_idx, image in enumerate(tqdm(images, desc="Processing pages")):
            # Convert image to bytes
            img_buffer = BytesIO()
            image.save(img_buffer, format="PNG")
            img_base64 = base64.b64encode(img_buffer.getvalue()).decode('utf-8')
            img_buffer.close()
            
            file_size = len(img_base64) / (1024 * 1024)  # MB
            print(f"ğŸ“„ Page {page_idx+1} image size: {file_size:.2f} MB")
            
            # ENHANCED: Prepare API request with multiple detection features
            api_url = f"https://vision.googleapis.com/v1/images:annotate?key={self.vision_api_key}"
            
            request_payload = {
                "requests": [
                    {
                        "image": {
                            "content": img_base64
                        },
                        "features": [
                            {
                                "type": "TEXT_DETECTION",
                                "maxResults": 100
                            },
                            {
                                "type": "DOCUMENT_TEXT_DETECTION"  # NEW: Better for structured content
                            },
                            {
                                "type": "OBJECT_LOCALIZATION",
                                "maxResults": 20
                            }
                        ],
                        "imageContext": {
                            "languageHints": ["gu", "en"]  # Gujarati and English
                        }
                    }
                ]
            }
            
            print(f"ğŸš€ Sending enhanced image request for page {page_idx+1} to Google Vision API...")
            headers = {'Content-Type': 'application/json'}
            response = requests.post(api_url, json=request_payload, headers=headers)
            
            # Count Vision API call
            self.api_calls["vision_api"] += 1
            print(f"ğŸ“Š Vision API Call #{self.api_calls['vision_api']} completed for page {page_idx+1}")
            
            if response.status_code != 200:
                print(f"âŒ Vision API Error for page {page_idx+1}: {response.status_code}")
                print(f"ğŸ” Error details: {response.text[:200]}...")
                pages_data.append({
                    "page_number": page_idx + 1,
                    "text": "",
                    "images": [],
                    "extracted_at": datetime.now().isoformat(),
                    "error": f"Vision API error: {response.status_code} - {response.text[:200]}"
                })
                continue
            
            result = response.json()
            print(f"ğŸ” API Response for page {page_idx+1}: {json.dumps(result, ensure_ascii=False, indent=2)[:500]}...")
            
            # ENHANCED: Process response with multiple detection methods
            page_data = self._process_enhanced_vision_response(result, page_idx + 1)
            pages_data.append(page_data)
            time.sleep(1)  # Rate limiting
        
        processing_time = time.time() - start_time
        total_images = sum(len(page.get('images', [])) for page in pages_data)
        total_characters = sum(len(page.get('text', '')) for page in pages_data)
        
        print("\nâœ… ENHANCED PDF EXTRACTION COMPLETED")
        print(f"ğŸ“„ Pages extracted: {len(pages_data)} / {len(images)}")
        print(f"ğŸ–¼ï¸ Images/diagrams detected: {total_images}")
        print(f"ğŸ” Total characters extracted: {total_characters}")
        print(f"â±ï¸ Processing time: {processing_time:.2f} seconds")
        print(f"ğŸ“Š Total Vision API calls so far: {self.api_calls['vision_api']}")
        
        return pages_data

    def _process_enhanced_vision_response(self, result, page_number):
        """Process enhanced Vision API response with multiple detection methods"""
        print(f"ğŸ” Processing enhanced Vision API response for page {page_number}")
        
        page_data = {
            "page_number": page_number,
            "text": "",
            "images": [],
            "extracted_at": datetime.now().isoformat()
        }
        
        if 'responses' not in result or len(result['responses']) == 0:
            print(f"âš ï¸ No response data for page {page_number}")
            page_data["error"] = "No response data from Vision API"
            return page_data
        
        page_response = result['responses'][0]
        
        # Method 1: Extract text using TEXT_DETECTION (existing)
        if 'textAnnotations' in page_response and page_response['textAnnotations']:
            page_data["text"] = page_response['textAnnotations'][0].get('description', '')
            print(f"ğŸ“„ Page {page_number}: {len(page_data['text'])} characters extracted (TEXT_DETECTION)")
        else:
            print(f"âš ï¸ No textAnnotations for page {page_number}")
            page_data["error"] = "No text extracted from TEXT_DETECTION"
        
        # Method 2: Enhanced text extraction using DOCUMENT_TEXT_DETECTION
        if 'fullTextAnnotation' in page_response:
            document_text = page_response['fullTextAnnotation'].get('text', '')
            if len(document_text) > len(page_data["text"]):
                page_data["text"] = document_text
                print(f"ğŸ“„ Page {page_number}: Enhanced text extraction - {len(document_text)} characters (DOCUMENT_TEXT_DETECTION)")
        
        # Method 3: Object detection (existing but enhanced)
        detected_objects = []
        if 'localizedObjectAnnotations' in page_response:
            for obj in page_response['localizedObjectAnnotations']:
                print(f"ğŸ–¼ï¸ Page {page_number}: Detected object '{obj['name']}' (confidence: {obj.get('score', 0):.2f})")
                # Enhanced object type detection
                if self._is_mathematical_content(obj['name']):
                    detected_objects.append({
                        "object_type": obj['name'],
                        "confidence": obj.get('score', 0),
                        "detection_method": "vision_object_detection",
                        "raw_detection": obj['name']
                    })
                    print(f"ğŸ–¼ï¸ Page {page_number}: Added mathematical object '{obj['name']}' to detection list")
        
        # Store initial detections (will be enhanced by Gemini later)
        page_data["images"] = detected_objects
        
        chapter_name = getattr(self, "current_chapter", "àª…àªœà«àªàª¾àª¤ àª…àª§à«àª¯àª¾àª¯")  # You can set before processing
        ai_detected = self.detect_mathematical_content_with_ai(page_data["text"], chapter_name, page_number)

        for det in ai_detected:
            page_data["images"].append({
                "object_type": det,
                "confidence": 1.0,
                "detection_method": "gemini_ai_detection",
                "raw_detection": det
            })
        
        return page_data


    def _is_mathematical_content(self, object_name):
        """Check if detected object is likely mathematical content (English labels from Vision API)"""
        
        # English keywords (from Vision API object detection)
        english_mathematical_keywords = [
            'diagram', 'chart', 'graph', 'table', 'mathematical expression', 
            'formula', 'image', 'figure', 'equation', 'plot', 'grid',
            'coordinate', 'axis', 'line', 'curve', 'geometric', 'triangle',
            'circle', 'rectangle', 'polygon', 'shape', 'drawing', 'illustration'
        ]
        
        # Gujarati keywords (if Vision API occasionally returns Gujarati labels)
        gujarati_mathematical_keywords = [
            'àª†àª•à«ƒàª¤àª¿', 'àªšàª¾àª°à«àªŸ', 'àª†àª²à«‡àª–', 'àª•à«‹àª·à«àªŸàª•', 'àª¸à«‚àª¤à«àª°', 'àª¸àª®à«€àª•àª°àª£',
            'àª¤à«àª°àª¿àª•à«‹àª£', 'àªµàª°à«àª¤à«àª³', 'àªšàª¤à«àª°à«àª­à«àªœ', 'àª°à«‡àª–àª¾àª•à«ƒàª¤àª¿', 'àªšàª¿àª¤à«àª°'
        ]
        
        object_lower = object_name.lower()
        
        # Check English keywords (primary check)
        for keyword in english_mathematical_keywords:
            if keyword in object_lower:
                print(f"âœ… Mathematical content detected (English): '{object_name}' contains '{keyword}'")
                return True
        
        # Check Gujarati keywords (fallback check)
        for keyword in gujarati_mathematical_keywords:
            if keyword in object_name:
                print(f"âœ… Mathematical content detected (Gujarati): '{object_name}' contains '{keyword}'")
                return True
        
        print(f"âŒ Non-mathematical content: '{object_name}'")
        return False


        

    def detect_mathematical_content_with_ai(self, page_text, chapter_name, page_number):
        """Detect and describe mathematical diagrams in Gujarati with chapter-aware hints"""
        
        chapter_content_map = {
        "àªµàª¾àª¸à«àª¤àªµàª¿àª• àª¸àª‚àª–à«àª¯àª¾àª“": [
            "àª¸àª‚àª–à«àª¯àª¾ àª°à«‡àª–àª¾ àªªàª° àª¦àª°à«àª¶àª¾àªµà«‡àª²à«€ àª¸àª‚àª–à«àª¯àª¾àª“",
            "àª®à«‚àª³àª¾àª‚àª• àª¸àª¾àª¥à«‡ àª¸àª‚àª¬àª‚àª§àª¿àª¤ àª†àª•à«ƒàª¤àª¿àª“"
        ],
        "àª¬àª¹à«àªªàª¦à«€àª“": [
            "àª¬àª¹à«àªªàª¦à«€àª“àª¨àª¾ àª—à«àª°àª¾àª«",
            "àª®à«‚àª³ àª…àª¨à«‡ àª—à«àª£àª¾àª•àª¾àª° àª¦àª°à«àª¶àª¾àªµàª¤à«€ àª†àª•à«ƒàª¤àª¿àª“"
        ],
        "àª¦à«àªµàª¿àªšàª² àª¸à«àª°à«‡àª– àª¸àª®à«€àª•àª°àª£àª¯à«àª—à«àª®": [
            "àª¸àª®à«€àª•àª°àª£àª¨àª¾ àª—à«àª°àª¾àª«",
            "àª•à«‹àª·à«àªŸàª•",
            "àª°à«‡àª–àª¾àª“àª¨àª¾ intersection"
        ],
        "àª¦à«àªµàª¿àª˜àª¾àª¤ àª¸àª®à«€àª•àª°àª£": [
            "àªªà«‡àª°àª¾àª¬à«‹àª²àª¾àª¨à«‹ àª—à«àª°àª¾àª«",
            "àªµàª¿àª­àª¿àª¨à«àª¨ àª•à«‡àª¸ àª®àª¾àªŸà«‡àª¨àª¾ àª—à«àª°àª¾àª« (àªµàª¾àª¸à«àª¤àªµàª¿àª• àª®à«‚àª³, àª•àª²à«àªªàª¿àª¤ àª®à«‚àª³)",
            "àªµàª°à«àªŸà«‡àª•à«àª¸ àª¦àª°à«àª¶àª¾àªµàª¤à«‹ àª—à«àª°àª¾àª«"
        ],
        "àª¸àª®àª¾àª¨à«àª¤àª° àª¶à«àª°à«‡àª£à«€": [
            "àª…àª¨à«àª•à«àª°àª® àª¦àª°à«àª¶àª¾àªµàª¤à«€ àª•à«‹àª·à«àªŸàª•",
            "àª†àª¨à«àª•à«àª°àª®àª¿àª• àª¸àª‚àª–à«àª¯àª¾àª“ àª¦àª°à«àª¶àª¾àªµàª¤à«‹ àª†àª²à«‡àª–"
        ],
        "àª¤à«àª°àª¿àª•à«‹àª£": [
            "àª¤à«àª°àª¿àª•à«‹àª£àª¨à«€ àª°àªšàª¨àª¾",
            "àª¸àª®àª¾àª¨àª¤àª¾ àª¦àª°à«àª¶àª¾àªµàª¤à«€ àª†àª•à«ƒàª¤àª¿àª“",
            "àªªà«àª°àª®àª¾àª£ àª¦àª°à«àª¶àª¾àªµàª¤à«€ àª†àª•à«ƒàª¤àª¿àª“"
        ],
        "àª¯àª¾àª® àª­à«‚àª®àª¿àª¤àª¿": [
            "àª…àª•à«àª·àª¾àª‚àª•à«‹ àªªàª°àª¨àª¾ àª¬àª¿àª‚àª¦à«àª“",
            "àª…àª‚àª¤àª° àª¸à«‚àª¤à«àª°",
            "àªµàª¿àª­àª¾àª— àª¸à«‚àª¤à«àª°",
            "àª¤à«àª°àª¿àª•à«‹àª£àª¨à«àª‚ àª•à«àª·à«‡àª¤à«àª°àª«àª³ àª¦àª°à«àª¶àª¾àªµàª¤à«€ àª†àª•à«ƒàª¤àª¿"
        ],
        "àª¤à«àª°àª¿àª•à«‹àª£àª®àª¿àª¤àª¿ àª¨à«‹ àªªàª°àª¿àªšàª¯": [
            "àª¸àª®àª•à«‹àª£ àª¤à«àª°àª¿àª•à«‹àª£àª®àª¾àª‚ àª¤à«àª°àª¿àª•à«‹àª£àª®àª¿àª¤à«€àª¯ àª—à«àª£à«‹àª¤à«àª¤àª°",
            "àª¯à«‚àª¨àª¿àªŸ àª¸àª°à«àª•àª²"
        ],
        "àª¤à«àª°àª¿àª•à«‹àª£àª®àª¿àª¤àª¿ àª¨àª¾ àª‰àªªàª¯à«‹àª—à«‹": [
            "àªŠàª‚àªšàª¾àªˆ àª…àª¨à«‡ àª…àª‚àª¤àª° àª¦àª°à«àª¶àª¾àªµàª¤à«€ àª†àª•à«ƒàª¤àª¿àª“",
            "àª•à«‹àª£ àª‰àª¨à«àª¨àª¤àª¿ àª…àª¨à«‡ àª…àªµàª¨à«€àª¤àª¿"
        ],
        "àªµàª°à«àª¤à«àª³": [
            "àªµàª°à«àª¤à«àª³",
            "àª¸à«àªªàª°à«àª¶àª•",
            "àªœà«àª¯à«‹àª¤àª¿",
            "àª¤à«àª°àªœà«àª¯àª¾"
        ],
        "àª°àªšàª¨àª¾": [
            "àª•àª‚àªªàª¾àª¸àª¥à«€ àª°àªšàª¨àª¾",
            "àª•à«‹àª£ àª¦à«àªµàª¿àª­àª¾àªœàª•",
            "àª¤à«àª°àª¿àª•à«‹àª£àª¨à«€ àª°àªšàª¨àª¾"
        ],
        "àªµàª°à«àª¤à«àª³ àª¸àª‚àª¬àª‚àª§àª¿àª¤ àª•à«àª·à«‡àª¤à«àª°àª«àª³": [
            "àªµàª°à«àª¤à«àª³àª¨à«‹ àª•à«àª·à«‡àª¤à«àª°àª«àª³",
            "àª¸à«‡àª•à«àªŸàª°",
            "àª¸à«‡àª—àª®à«‡àª¨à«àªŸ"
        ],
        "àªªà«ƒàª·à«àª àª«àª³ àª…àª¨à«‡ àª˜àª¨àª«àª³": [
            "àª˜àª¨àª¾àª•à«ƒàª¤àª¿àª“àª¨àª¾ àª†àª²à«‡àª–",
            "àª¸àª¿àª²àª¿àª¨à«àª¡àª°",
            "àª¶àª‚àª•à«",
            "àª—à«‹àª³àª¾àª•àª¾àª°"
        ],
        "àª†àª‚àª•àª¡àª¾àª¶àª¾àª¸à«àª¤à«àª°": [
            "àª¹àª¿àª¸à«àªŸà«‹àª—à«àª°àª¾àª®",
            "àª¬àª¾àª° àªšàª¾àª°à«àªŸ",
            "àª†àªµàª°à«àª¤àª¨ àª•à«‹àª·à«àªŸàª•",
            "àªªàª¾àªˆ àªšàª¾àª°à«àªŸ"
        ],
        "àª¸àª‚àª­àª¾àªµàª¨àª¾": [
            "àª¸àª‚àª­àª¾àªµàª¨àª¾ àªµà«ƒàª•à«àª·",
            "àªªà«àª°àª¯à«‹àª—à«‹àª¨àª¾ àª†àª•à«ƒàª¤àª¿àª“",
            "àª¨àª®à«‚àª¨àª¾ àª¸à«àª¥àª¾àª¨"
            ]
        }
        
        expected_content = chapter_content_map.get(chapter_name, [])
        
        prompt = f"""
        àª¤àª®à«‡ àª§à«‹àª°àª£ 10 àª—àª£àª¿àª¤àª¨àª¾ àªªàª¾àª à«àª¯àªªà«àª¸à«àª¤àª•àª¨àª¾ àª…àª§à«àª¯àª¾àª¯ "{chapter_name}" àª¨à«àª‚ àªªàª¾àª¨à«àª‚ {page_number} àªµàª¾àª‚àªšà«€ àª°àª¹à«àª¯àª¾ àª›à«‹. 

        àª† àª…àª§à«àª¯àª¾àª¯àª®àª¾àª‚ àª¸àª¾àª®àª¾àª¨à«àª¯ àª°à«€àª¤à«‡ àªœà«‹àªµàª¾ àª®àª³àª¤à«€ àª†àª•à«ƒàª¤àª¿àª“: {', '.join(expected_content)}.

        àª¨à«€àªšà«‡àª¨àª¾ àª²àª–àª¾àª£àª¨à«‡ àª†àª§àª¾àª°à«‡ àª“àª³àª–à«‹ àª•à«‡ àª† àªªàª¾àª¨àª¾àª®àª¾àª‚ àª•àªˆ àª†àª•à«ƒàª¤àª¿àª“ àª›à«‡. 
        àª¦àª°à«‡àª• àª®àª¾àªŸà«‡ àª¸à«àªªàª·à«àªŸ àª—à«àªœàª°àª¾àª¤à«€ àªµàª°à«àª£àª¨ àª…àª¨à«‡ àª¶à«ˆàª•à«àª·àª£àª¿àª• àª¹à«‡àª¤à« àª†àªªà«‹.

        àª²àª–àª¾àª£:
        {page_text}

        àª«àª•à«àª¤ àª† àª«à«‹àª°à«àª®à«‡àªŸàª®àª¾àª‚ JSON return àª•àª°à«‹ (àª•à«‹àªˆ àªµàª§àª¾àª°àª¾àª¨à«‹ àª²àª–àª¾àª£ àª¨àª¹à«€àª‚):
        [
        {{
            "description": "x + y = 5 àª¨à«àª‚ àª¸à«àª°à«‡àª– àª¸àª®à«€àª•àª°àª£ àª¦àª°à«àª¶àª¾àªµàª¤à«‹ àª—à«àª°àª¾àª« àªœà«‡àª®àª¾àª‚ àª°à«‡àª–àª¾ (0,5) àª…àª¨à«‡ (5,0) àªªàª°àª¥à«€ àªªàª¸àª¾àª° àª¥àª¾àª¯ àª›à«‡.",
            "educational_context": "àªµàª¿àª¦à«àª¯àª¾àª°à«àª¥à«€àª“ àª¸àª®à«€àª•àª°àª£àª¨à«‡ àª—à«àª°àª¾àª«àª¿àª• àª°à«€àª¤à«‡ àª•à«‡àªµà«€ àª°à«€àª¤à«‡ àª°àªœà«‚ àª¥àª¾àª¯ àª›à«‡ àª¤à«‡ àª¸àª®àªœà«€ àª¶àª•à«‡ àª›à«‡."
        }}
        ]
        àªœà«‹ àª†àª•à«ƒàª¤àª¿ àª¨ àª¹à«‹àª¯ àª¤à«‹ àª–àª¾àª²à«€ array [] return àª•àª°à«‹.
        """
        
        response = self.gemini_model.generate_content(prompt)
        text = response.text.strip()
        
        # ğŸ› ï¸ Clean out markdown fences if Gemini adds them
        if text.startswith("```"):
            text = text.strip("`")
            if text.lower().startswith("json"):
                text = text[4:].strip()
        
        try:
            detections = json.loads(text)
            return detections if isinstance(detections, list) else []
        except Exception:
            print(f"âš ï¸ Gemini response parsing error (cleaned): {text[:200]}")
            return []

  
    def describe_images_with_ai(self, pages_data):
        """Generate educational descriptions for detected images using Gemini API"""
        print("\n" + "="*50)
        print("ğŸ–¼ï¸ STEP 2: IMAGE DESCRIPTION GENERATION")
        print("="*50)
        
        total_images = sum(len(page.get('images', [])) for page in pages_data)
        print(f"ğŸ–¼ï¸ Total images to describe: {total_images}")
        print(f"ğŸ“Š Current API calls - Vision: {self.api_calls['vision_api']}, Gemini: {self.api_calls['gemini_api']}")
        
        if total_images == 0:
            print("â„¹ï¸ No images detected. Skipping image description step.")
            return pages_data
        
        start_time = time.time()
        successful_descriptions = 0
        failed_descriptions = 0
        
        for page in tqdm(pages_data, desc="Describing images"):
            if not page.get("images"):
                print(f"ğŸ“„ Page {page['page_number']}: No images to describe")
                continue
            
            print(f"ğŸ“„ Page {page['page_number']}: Processing {len(page['images'])} images")
            for image in page["images"]:
                try:
                    object_type = image["object_type"]
                    confidence = image["confidence"]
                    context = f"Page {page['page_number']} of Class 10 Mathematics textbook"
                    
                    prompt = self.prompts["image_description"].format(
                        image_content=f"{object_type} (confidence: {confidence:.2f})",
                        context=context
                    )
                    
                    print(f"  ğŸ”„ Sending image description request for {object_type} to Gemini API...")
                    response = self.gemini_model.generate_content(prompt)
                    
                    self.api_calls["gemini_api"] += 1
                    successful_descriptions += 1
                    
                    image["educational_description"] = response.text
                    print(f"  âœ… Description generated for {object_type} ({len(response.text)} characters)")
                    
                    time.sleep(1)
                except Exception as e:
                    failed_descriptions += 1
                    print(f"  âŒ Error describing {object_type}: {str(e)[:100]}...")
                    image["educational_description"] = "àªµàª°à«àª£àª¨ àª‰àªªàª²àª¬à«àª§ àª¨àª¥à«€"
        
        processing_time = time.time() - start_time
        
        print("\nâœ… IMAGE DESCRIPTION COMPLETED")
        print(f"ğŸ–¼ï¸ Successful descriptions: {successful_descriptions}")
        print(f"âŒ Failed descriptions: {failed_descriptions}")
        print(f"â±ï¸ Processing time: {processing_time:.2f} seconds")
        print(f"ğŸ“Š Gemini API calls for descriptions: {successful_descriptions}")
        print(f"ğŸ“Š Total Gemini API calls so far: {self.api_calls['gemini_api']}")
        
        return pages_data
    
    def integrate_images_in_text(self, pages_data):
        """Integrate image references into page text"""
        print("\n" + "="*50)
        print("ğŸ”— STEP 3: TEXT-IMAGE INTEGRATION")
        print("="*50)
        
        total_pages_with_images = sum(1 for page in pages_data if page.get("images"))
        total_image_refs = sum(len(page.get("images", [])) for page in pages_data)
        
        print(f"ğŸ“„ Pages with images: {total_pages_with_images}")
        print(f"ğŸ”— Image references to add: {total_image_refs}")
        
        if total_image_refs == 0:
            print("â„¹ï¸ No images to integrate. Skipping integration step.")
            return pages_data
        
        start_time = time.time()
        integrated_count = 0
        
        for page in pages_data:
            if page["images"]:
                print(f"ğŸ“„ Page {page['page_number']}: Integrating {len(page['images'])} image references")
                
                image_refs = []
                for i, image in enumerate(page["images"], 1):
                    ref_text = f"\n[àªšàª¿àª¤à«àª° {i}: {image['educational_description']}]"
                    image_refs.append(ref_text)
                    integrated_count += 1
                
                original_length = len(page["text"])
                page["text"] += "".join(image_refs)
                new_length = len(page["text"])
                
                print(f"  âœ… Added {len(image_refs)} references (+{new_length - original_length} characters)")
                
                for i, image in enumerate(page["images"], 1):
                    image["reference_id"] = f"àªšàª¿àª¤à«àª°_{page['page_number']}_{i}"
        
        processing_time = time.time() - start_time
        
        print("\nâœ… TEXT-IMAGE INTEGRATION COMPLETED")
        print(f"ğŸ”— Total image references integrated: {integrated_count}")
        print(f"â±ï¸ Processing time: {processing_time:.2f} seconds")
        print("ğŸ“Š No API calls required for this step")
        
        return pages_data
    
    def summarize_pages(self, pages_data):
        """Summarize each page using Gemini with image context"""
        print("\n" + "="*50)
        print("ğŸ“ STEP 4: PAGE-WISE SUMMARIZATION")
        print("="*50)
        
        print(f"ğŸ“„ Total pages to summarize: {len(pages_data)}")
        print(f"ğŸ“Š Current API calls - Vision: {self.api_calls['vision_api']}, Gemini: {self.api_calls['gemini_api']}")
        
        start_time = time.time()
        successful_summaries = 0
        failed_summaries = 0
        
        for page in tqdm(pages_data, desc="ğŸ“ Summarizing pages"):
            try:
                print(f"\nğŸ“„ Processing Page {page['page_number']}")
                
                image_descriptions = ""
                if page["images"]:
                    descriptions = [img["educational_description"] for img in page["images"]]
                    image_descriptions = "\n".join(descriptions)
                    print(f"  ğŸ–¼ï¸ Including {len(page['images'])} image descriptions")
                else:
                    image_descriptions = "àª† àªªàª¾àª¨àª¾àª®àª¾àª‚ àª•à«‹àªˆ àªšàª¿àª¤à«àª° àª¨àª¥à«€."
                    print("  ğŸ“„ No images on this page")
                
                text_length = len(page["text"])
                print(f"  ğŸ“Š Text length: {text_length} characters")
                
                prompt = self.prompts["page_summarization"].format(
                    page_text=page["text"],
                    image_descriptions=image_descriptions
                )
                
                print(f"  ğŸ”„ Sending to Gemini API...")
                response = self.gemini_model.generate_content(prompt)
                
                self.api_calls["gemini_api"] += 1
                successful_summaries += 1
                
                page["page_summary"] = response.text
                page["summarized_at"] = datetime.now().isoformat()
                
                summary_length = len(response.text)
                print(f"  âœ… Summary generated ({summary_length} characters) - API call #{self.api_calls['gemini_api']}")
                
                time.sleep(1)
            except Exception as e:
                failed_summaries += 1
                print(f"  âŒ Error: {str(e)[:100]}...")
                page["page_summary"] = "àª¸àª¾àª°àª¾àª‚àª¶ àª‰àªªàª²àª¬à«àª§ àª¨àª¥à«€"
        
        processing_time = time.time() - start_time
        
        print("\nâœ… PAGE SUMMARIZATION COMPLETED")
        print(f"ğŸ“ Successful summaries: {successful_summaries}")
        print(f"âŒ Failed summaries: {failed_summaries}")
        print(f"â±ï¸ Processing time: {processing_time:.2f} seconds")
        print(f"ğŸ“Š Gemini API calls for summaries: {successful_summaries}")
        print(f"ğŸ“Š Total Gemini API calls so far: {self.api_calls['gemini_api']}")
        
        return pages_data
    
    def analyze_chapter(self, pages_data):
        """Generate chapter analysis from all page summaries"""
        print("\n" + "="*50)
        print("ğŸ“š STEP 5: CHAPTER ANALYSIS")
        print("="*50)
        
        page_summaries = []
        valid_summaries = 0
        
        for page in pages_data:
            if 'page_summary' in page and page['page_summary'] != "àª¸àª¾àª°àª¾àª‚àª¶ àª‰àªªàª²àª¬à«àª§ àª¨àª¥à«€":
                page_summaries.append(f"àªªàª¾àª¨à«àª‚ {page['page_number']}: {page['page_summary']}")
                valid_summaries += 1
        
        print(f"ğŸ“„ Valid page summaries: {valid_summaries}/{len(pages_data)}")
        print(f"ğŸ“Š Current API calls - Vision: {self.api_calls['vision_api']}, Gemini: {self.api_calls['gemini_api']}")
        
        if not page_summaries:
            print("âŒ No valid page summaries found. Cannot analyze chapter.")
            return {"chapter_summary": "àª…àª§à«àª¯àª¾àª¯ àªµàª¿àª¶à«àª²à«‡àª·àª£àª®àª¾àª‚ àª­à«‚àª² - àª•à«‹àªˆ àª¸àª¾àª°àª¾àª‚àª¶ àª‰àªªàª²àª¬à«àª§ àª¨àª¥à«€", "analyzed_at": datetime.now().isoformat()}
        
        summaries_text = "\n\n".join(page_summaries)
        total_chars = len(summaries_text)
        print(f"ğŸ“Š Total summary text: {total_chars} characters")
        
        start_time = time.time()
        
        try:
            print("ğŸ”„ Sending chapter analysis request to Gemini API...")
            
            prompt = self.prompts["chapter_analysis"].format(
                page_summaries=summaries_text
            )
            
            response = self.gemini_model.generate_content(prompt)
            self.api_calls["gemini_api"] += 1
            
            analysis_text = response.text
            analysis_length = len(analysis_text)
            
            processing_time = time.time() - start_time
            
            print(f"âœ… Chapter analysis completed ({analysis_length} characters)")
            print(f"â±ï¸ Processing time: {processing_time:.2f} seconds")
            print(f"ğŸ“Š API call #{self.api_calls['gemini_api']} - Chapter Analysis")
            print(f"ğŸ“Š Total Gemini API calls so far: {self.api_calls['gemini_api']}")
            
            return {
                "chapter_summary": analysis_text,
                "analyzed_at": datetime.now().isoformat()
            }
        except Exception as e:
            processing_time = time.time() - start_time
            print(f"âŒ Error in chapter analysis: {str(e)[:100]}...")
            print(f"â±ï¸ Failed after: {processing_time:.2f} seconds")
            
            return {
                "chapter_summary": "àª…àª§à«àª¯àª¾àª¯ àªµàª¿àª¶à«àª²à«‡àª·àª£àª®àª¾àª‚ àª­à«‚àª²",
                "analyzed_at": datetime.now().isoformat()
            }
    
    def extract_topics_from_analysis(self, chapter_info):
        """Extract topics list from chapter analysis"""
        print("\n" + "="*50)
        print("ğŸ“‹ STEP 6: TOPIC EXTRACTION")
        print("="*50)
        
        analysis = chapter_info["chapter_summary"]
        print(f"ğŸ“Š Analyzing {len(analysis)} characters of chapter summary")
        
        topics = []
        lines = analysis.split('\n')
        
        print("ğŸ” Searching for topics in chapter analysis...")
        
        for line in lines:
            line = line.strip()
            if line and (line[0].isdigit() or line.startswith('- ')):
                topic = line.lstrip('0123456789.- ').strip()
                if topic and len(topic) > 5:
                    topics.append(topic)
                    print(f"  âœ… Topic {len(topics)}: {topic[:50]}...")
        
        print(f"\nğŸ“‹ TOPIC EXTRACTION COMPLETED")
        print(f"ğŸ¯ Topics extracted: {len(topics)}")
        
        if len(topics) == 0:
            print("âš ï¸ No topics found in chapter analysis. Creating default topics...")
            topics = ["àª¸àª¾àª®àª¾àª¨à«àª¯ àª—àª£àª¿àª¤à«€àª¯ àª¸àª‚àª•àª²à«àªªàª¨àª¾àª“", "àª¸à«‚àª¤à«àª°à«‹ àª…àª¨à«‡ àª—àª£àª¤àª°à«€", "àª‰àª¦àª¾àª¹àª°àª£à«‹ àª…àª¨à«‡ àª•àª¸à«‹àªŸà«€àª“"]
        
        print("ğŸ“Š No API calls required for topic extraction")
        
        print("\nğŸ“‹ EXTRACTED TOPICS:")
        for i, topic in enumerate(topics, 1):
            print(f"  {i}. {topic}")
        
        return topics
    
    def assign_topics_to_pages(self, pages_data, topics_list):
        """Assign non-overlapping topics to each page"""
        print("\n" + "="*50)
        print("ğŸ·ï¸ STEP 7: TOPIC ASSIGNMENT")
        print("="*50)
        
        print(f"ğŸ“„ Pages to process: {len(pages_data)}")
        print(f"ğŸ¯ Available topics: {len(topics_list)}")
        print(f"ğŸ“Š Current API calls - Vision: {self.api_calls['vision_api']}, Gemini: {self.api_calls['gemini_api']}")
        
        topics_with_numbers = []
        for i, topic in enumerate(topics_list, 1):
            topics_with_numbers.append(f"{i}. {topic}")
        
        topics_string = "\n".join(topics_with_numbers)
        print(f"ğŸ“‹ Topics formatted for AI assignment")
        
        start_time = time.time()
        successful_assignments = 0
        failed_assignments = 0
        total_topic_assignments = 0
        
        for page in tqdm(pages_data, desc="ğŸ·ï¸ Assigning topics"):
            try:
                print(f"\nğŸ“„ Processing Page {page['page_number']}")
                
                text_length = len(page["text"])
                text_sample = page["text"][:2000]
                
                print(f"  ğŸ“Š Text length: {text_length} characters (using first 2000)")
                
                prompt = self.prompts["topic_assignment"].format(
                    page_text=text_sample,
                    topics_list=topics_string
                )
                
                print(f"  ğŸ”„ Sending to Gemini API...")
                response = self.gemini_model.generate_content(prompt)
                
                self.api_calls["gemini_api"] += 1
                successful_assignments += 1
                
                topic_numbers = []
                response_text = response.text.strip()
                
                print(f"  ğŸ“ AI Response: {response_text[:50]}...")
                
                for part in response_text.split(','):
                    try:
                        num = int(part.strip())
                        if 1 <= num <= len(topics_list) and num not in topic_numbers:
                            topic_numbers.append(num)
                    except ValueError:
                        continue
                
                page["assigned_topics"] = topic_numbers
                page["topics_assigned_at"] = datetime.now().isoformat()
                
                total_topic_assignments += len(topic_numbers)
                print(f"  âœ… Assigned {len(topic_numbers)} topics: {topic_numbers} - API call #{self.api_calls['gemini_api']}")
                
                time.sleep(1)
            except Exception as e:
                failed_assignments += 1
                print(f"  âŒ Error: {str(e)[:100]}...")
                page["assigned_topics"] = []
        
        processing_time = time.time() - start_time
        avg_topics_per_page = total_topic_assignments / len(pages_data) if pages_data else 0
        
        print("\nâœ… TOPIC ASSIGNMENT COMPLETED")
        print(f"ğŸ“„ Successful assignments: {successful_assignments}")
        print(f"âŒ Failed assignments: {failed_assignments}")
        print(f"ğŸ¯ Total topic assignments: {total_topic_assignments}")
        print(f"ğŸ“Š Average topics per page: {avg_topics_per_page:.1f}")
        print(f"â±ï¸ Processing time: {processing_time:.2f} seconds")
        print(f"ğŸ“Š Gemini API calls for topic assignment: {successful_assignments}")
        print(f"ğŸ“Š Total Gemini API calls so far: {self.api_calls['gemini_api']}")
        
        return pages_data
    
    def save_results(self, pdf_path, pages_data, chapter_info, topics_list):
        """Save all results to single JSON file"""
        print("\n" + "="*50)
        print("ğŸ’¾ STEP 8: SAVE RESULTS")
        print("="*50)
        
        processing_end_time = datetime.now()
        total_processing_time = (processing_end_time - self.api_calls["start_time"]).total_seconds()
        
        total_images = sum(len(page.get('images', [])) for page in pages_data)
        total_characters = sum(len(page.get('text', '')) for page in pages_data)
        total_topic_assignments = sum(len(page.get('assigned_topics', [])) for page in pages_data)
        
        print(f"ğŸ“Š FINAL PROCESSING STATISTICS:")
        print(f"  ğŸ“„ Total pages: {len(pages_data)}")
        print(f"  ğŸ–¼ï¸ Total images: {total_images}")
        print(f"  ğŸ“ Total characters extracted: {total_characters:,}")
        print(f"  ğŸ¯ Total topics extracted: {len(topics_list)}")
        print(f"  ğŸ·ï¸ Total topic assignments: {total_topic_assignments}")
        print(f"  â±ï¸ Total processing time: {total_processing_time:.2f} seconds")
        
        output_data = {
            "metadata": {
                "source_pdf": os.path.basename(pdf_path),
                "board": "GSEB",
                "class": 10,
                "subject": "Mathematics",
                "medium": "Gujarati",
                "processed_at": processing_end_time.isoformat(),
                "total_pages": len(pages_data),
                "total_topics": len(topics_list),
                "total_images": total_images,
                "total_characters": total_characters,
                "processing_time_seconds": round(total_processing_time, 2),
                "api_usage": {
                    "vision_api_calls": self.api_calls["vision_api"],
                    "gemini_api_calls": self.api_calls["gemini_api"],
                    "total_api_calls": self.api_calls["vision_api"] + self.api_calls["gemini_api"]
                }
            },
            "chapter_info": {
                **chapter_info,
                "extracted_topics": topics_list
            },
            "pages": pages_data
        }
        
        base_name = os.path.splitext(os.path.basename(pdf_path))[0]
        timestamp = processing_end_time.strftime("%Y%m%d_%H%M%S")
        output_filename = f"gseb_class10_maths_{base_name}_{timestamp}.json"
        
        print(f"ğŸ“ Saving to file: {output_filename}")
        
        try:
            with open(output_filename, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            file_size = os.path.getsize(output_filename) / (1024 * 1024)
            
            print(f"âœ… SAVE COMPLETED")
            print(f"ğŸ’¾ File size: {file_size:.2f} MB")
            print(f"ğŸ“Š API USAGE SUMMARY:")
            print(f"  ğŸ” Google Vision API calls: {self.api_calls['vision_api']}")
            print(f"  ğŸ§  Google Gemini API calls: {self.api_calls['gemini_api']}")
            print(f"  ğŸ“Š Total API calls: {self.api_calls['vision_api'] + self.api_calls['gemini_api']}")
            
            return output_filename
        except Exception as e:
            print(f"âŒ Error saving file: {str(e)}")
            return None
    
    def process_pdf(self, pdf_path):
        """Main processing pipeline with comprehensive logging and API counting"""
        print("\n" + "="*70)
        print("ğŸš€ GSEB PDF PROCESSING PIPELINE STARTED")
        print("="*70)
        print(f"ğŸ“„ File: {os.path.basename(pdf_path)}")
        print(f"ğŸ“š Target: Class 10 Mathematics (Gujarati Medium)")
        print(f"ğŸ• Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ“Š Initial API counters - Vision: 0, Gemini: 0")
        
        try:
            # Step 1: Extract PDF pages with images
            pages_data = self.extract_pdf_with_images(pdf_path)
            
            if not pages_data:
                print("\nâŒ PIPELINE FAILED: No pages extracted")
                return None
            
            # Step 2: Generate AI descriptions for images/diagrams
            pages_data = self.describe_images_with_ai(pages_data)
            
            # Step 3: Integrate image references into text
            pages_data = self.integrate_images_in_text(pages_data)
            
            # Step 4: Summarize each page (with image context)
            pages_data = self.summarize_pages(pages_data)
            
            # Step 5: Analyze complete chapter
            chapter_info = self.analyze_chapter(pages_data)
            
            # Step 6: Extract topics from analysis
            topics_list = self.extract_topics_from_analysis(chapter_info)
            
            # Step 7: Assign topics to pages
            pages_data = self.assign_topics_to_pages(pages_data, topics_list)
            
            # Step 8: Save complete results
            output_file = self.save_results(pdf_path, pages_data, chapter_info, topics_list)
            
            if not output_file:
                print("\nâŒ PIPELINE FAILED: Could not save results")
                return None
            
            total_images = sum(len(page.get('images', [])) for page in pages_data)
            total_characters = sum(len(page.get('text', '')) for page in pages_data)
            
            try:
                total_processing_time = (datetime.now() - self.api_calls["start_time"]).total_seconds()
                vision_calls = self.api_calls['vision_api']
                gemini_calls = self.api_calls['gemini_api']
            except (AttributeError, KeyError):
                total_processing_time = 0
                vision_calls = 0
                gemini_calls = 0
            
            print("\n" + "="*70)
            print("ğŸ‰ PIPELINE COMPLETED SUCCESSFULLY!")
            print("="*70)
            print(f"ğŸ“Š FINAL STATISTICS:")
            print(f"  ğŸ“„ Pages processed: {len(pages_data)}")
            print(f"  ğŸ–¼ï¸ Images processed: {total_images}")
            print(f"  ğŸ“ Characters extracted: {total_characters:,}")
            print(f"  ğŸ¯ Topics extracted: {len(topics_list)}")
            if total_processing_time > 0:
                print(f"  â±ï¸ Total processing time: {total_processing_time:.2f} seconds")
            print(f"ğŸ“Š API USAGE:")
            print(f"  ğŸ” Google Vision API calls: {vision_calls}")
            print(f"  ğŸ§  Google Gemini API calls: {gemini_calls}")
            print(f"  ğŸ“Š Total API calls: {vision_calls + gemini_calls}")
            print(f"ğŸ’¾ Output file: {output_file}")
            print("="*70)
            
            return output_file
        except Exception as e:
            try:
                total_processing_time = (datetime.now() - self.api_calls["start_time"]).total_seconds()
                vision_calls = self.api_calls['vision_api']
                gemini_calls = self.api_calls['gemini_api']
            except (AttributeError, KeyError):
                total_processing_time = 0
                vision_calls = 0
                gemini_calls = 0
            
            print("\n" + "="*70)
            print("âŒ PIPELINE FAILED!")
            print("="*70)
            print(f"ğŸš« Error: {str(e)}")
            if total_processing_time > 0:
                print(f"â±ï¸ Failed after: {total_processing_time:.2f} seconds")
            print(f"ğŸ“Š API calls made before failure:")
            print(f"  ğŸ” Google Vision API: {vision_calls}")
            print(f"  ğŸ§  Google Gemini API: {gemini_calls}")
            print("="*70)
            
            return None

def main():
    """Main execution function"""
    print("ğŸ“š GSEB Question Paper Generation System")
    print("ğŸ”§ PDF Processing Module - Class 10 Maths (Gujarati)")
    print("âœ¨ With Image Recognition & Educational Descriptions")
    print("=" * 70)
    
    # Initialize processor
    try:
        processor = GSEBPDFProcessor()
        
    except ValueError as e:
        print(f"âŒ Initialization Error: {str(e)}")
        print("Please check your .env file and API keys.")
        return
    
    # Get PDF file path from user
    pdf_path = input("\nğŸ“ Enter the path to your Class 10 Maths Gujarati PDF: ").strip()
    
    if not os.path.exists(pdf_path):
        print("âŒ File not found! Please check the path.")
        return
    
    processor.current_chapter = "àª¦à«àªµàª¿àªšàª² àª¸à«àª°à«‡àª– àª¸àª®à«€àª•àª°àª£àª¯à«àª—à«àª®"
    # Process the PDF
    result = processor.process_pdf(pdf_path)
    
    if result:
        print(f"\nâœ… SUCCESS! Check the output file: {result}")
        print("\nğŸ“– The file contains:")
        print("   â€¢ Page-by-page text extraction")  
        print("   â€¢ Educational image descriptions")
        print("   â€¢ Comprehensive page summaries")
        print("   â€¢ Complete chapter analysis")
        print("   â€¢ Topic extraction and assignment")
    else:
        print("\nâŒ Processing failed! Check the error messages above.")

if __name__ == "__main__":
    main()