import os
import json
import time
import requests
import base64
from datetime import datetime
import google.generativeai as genai
from dotenv import load_dotenv
from tqdm import tqdm
from pypdf import PdfReader, PdfWriter  # For PDF page count
from pdf2image import convert_from_path  # For converting PDF to images
from io import BytesIO

# Load environment variables
load_dotenv()

class GSEBPDFProcessor:
    def __init__(self):
        # Initialize Google Cloud Vision API key
        self.vision_api_key = os.getenv('GOOGLE_CLOUD_VISION_API_KEY')
        if not self.vision_api_key:
            raise ValueError("GOOGLE_CLOUD_VISION_API_KEY not found in environment variables")
        
        # Initialize Gemini
        gemini_api_key = os.getenv('GEMINI_API_KEY')
        if not gemini_api_key:
            raise ValueError("GEMINI_API_KEY not found in environment variables")
            
        genai.configure(api_key=gemini_api_key)
        self.gemini_model = genai.GenerativeModel('gemini-2.0-flash')
        
        # API call counters
        self.api_calls = {
            "vision_api": 0,
            "gemini_api": 0,
            "total_tokens_used": 0,
            "start_time": datetime.now()
        }
        
        # Class 10 Maths Gujarati specific prompts
        self.prompts = self._load_subject_prompts()
        
        print("ЁЯФз Initialized GSEB PDF Processor")
        print(f"ЁЯФС Vision API Key: {'тЬЕ Loaded' if self.vision_api_key else 'тЭМ Missing'}")
        print(f"ЁЯФС Gemini API Key: {'тЬЕ Loaded' if gemini_api_key else 'тЭМ Missing'}")
        print("ЁЯУК API Call Counter: Initialized")
        
    def _load_subject_prompts(self):
        """Load Class 10 Mathematics Gujarati specific prompts"""
        return {
            "page_summarization": """
            ркдркорлЗ рк╡рк░рлНркЧ 10ркирк╛ ркЧркгрк┐ркд рк╡рк┐рк╖ркпркирлБркВ рккрлБрк╕рлНркдркХ (ркЧрлБркЬрк░рк╛ркдрлА ркорк╛ркзрлНркпрко) ркирлБркВ рк╡рк┐рк╢рлНрк▓рлЗрк╖ркг ркХрк░рлЛ ркЫрлЛ.
            ркЖ рккрк╛ркирк╛ркирлА рк╕рк╛ркоркЧрлНрк░рлАркирлЛ рк╕рк╛рк░рк╛ркВрк╢ ркЧрлБркЬрк░рк╛ркдрлАркорк╛ркВ ркЖрккрлЛ, ркЬрлЗркорк╛ркВ ркирлАркЪрлЗркирлА ркмрк╛ркмркдрлЛ рк╕ркорк╛рк╡рлЗрк╢ ркХрк░рлЛ:
            
            - ркорлБркЦрлНркп ркЧркгрк┐ркдрлАркп рк╕ркВркХрк▓рлНрккркирк╛ркУ (Key mathematical concepts)
            - рк╕рлВркдрлНрк░рлЛ ркЕркирлЗ ркирк┐ркпркорлЛ (Formulas and rules)
            - ркЙркжрк╛рк╣рк░ркгрлЛ (Examples) - ркЬрлЛ ркХрлЛркИ рк╣рлЛркп ркдрлЛ
            - ркХрк╕рлЛркЯрлАркУ (Exercises) - ркЬрлЛ ркХрлЛркИ рк╣рлЛркп ркдрлЛ  
            - ркЪрк┐ркдрлНрк░рлЛ/ркЖркХрлГркдрк┐ркУ (Diagrams) - ркЬрлЛ ркХрлЛркИ рк╣рлЛркп ркдрлЛ
            
            рккрк╛ркирк╛ркирлА рк╕рк╛ркоркЧрлНрк░рлА: {page_text}
            
            ркЪрк┐ркдрлНрк░рлЛркирлА ркорк╛рк╣рк┐ркдрлА: {image_descriptions}
            
            ркЧрлБркЬрк░рк╛ркдрлАркорк╛ркВ рк╕рк╛рк░рк╛ркВрк╢ ркЖрккрлЛ:
            """,
            "chapter_analysis": """
            ркдркорлЗ рк╡рк░рлНркЧ 10ркирк╛ ркЧркгрк┐ркд ркЕркзрлНркпрк╛ркпркирлБркВ рк╡рк┐рк╢рлНрк▓рлЗрк╖ркг ркХрк░рлЛ ркЫрлЛ. ркдркорк╛рко рккрк╛ркирк╛ркУркирк╛ рк╕рк╛рк░рк╛ркВрк╢ркирк╛ ркЖркзрк╛рк░рлЗ ркирлАркЪрлЗркирлА ркорк╛рк╣рк┐ркдрлА ркЖрккрлЛ:
            
            рккрк╛ркирк╛ркУркирк╛ рк╕рк╛рк░рк╛ркВрк╢: {page_summaries}
            
            ркХрлГрккрк╛ ркХрк░рлАркирлЗ ркЖрккрлЛ:
            
            **ркЕркзрлНркпрк╛ркпркирлЛ рк╕ркВрккрлВрк░рлНркг рк╕рк╛рк░рк╛ркВрк╢:**
            [рк╕ркВрккрлВрк░рлНркг ркЕркзрлНркпрк╛ркпркирлЛ рк╕рк╛рк░рк╛ркВрк╢]
            
            **ркорлБркЦрлНркп рк╡рк┐рк╖ркпрлЛркирлА ркпрк╛ркжрлА:**
            1. [рк╡рк┐рк╖ркп 1]
            2. [рк╡рк┐рк╖ркп 2]
            3. [рк╡рк┐рк╖ркп 3]
            
            **рк╢рлАркЦрк╡рк╛ркирк╛ рккрк░рк┐ркгрк╛ркорлЛ:**
            - [рккрк░рк┐ркгрк╛рко 1]
            - [рккрк░рк┐ркгрк╛рко 2]
            """,
            "topic_assignment": """
            ркЖ рккрк╛ркирк╛ркирлА рк╕рк╛ркоркЧрлНрк░рлА ркЕркирлЗ рк╡рк┐рк╖ркпрлЛркирлА ркпрк╛ркжрлАркирк╛ ркЖркзрк╛рк░рлЗ, ркЖ рккрк╛ркирк╛ркирлЗ рк╕ркВркмркВркзрк┐ркд рк╡рк┐рк╖ркпрлЛркирк╛ ркиркВркмрк░ ркЖрккрлЛ.
            
            ркирк┐ркпркорлЛ:
            - ркПркХ рккрк╛ркирк╛ркорк╛ркВ ркмрк╣рлБрк╡рк┐ркз рк╡рк┐рк╖ркпрлЛ рк╣рлЛркИ рк╢ркХрлЗ
            - ркПркХ ркЬ рк╡рк┐рк╖ркп ркмрлЗ рк╡ркЦркд рки ркЖрк╡рк╡рлЛ ркЬрлЛркИркП
            - рклркХрлНркд рк╕рлМркерлА рк╕ркВркмркВркзрк┐ркд рк╡рк┐рк╖ркпрлЛ рккрк╕ркВркж ркХрк░рлЛ
            
            рккрк╛ркирк╛ркирлА рк╕рк╛ркоркЧрлНрк░рлА: {page_text}
            
            ркЙрккрк▓ркмрлНркз рк╡рк┐рк╖ркпрлЛ:
            {topics_list}
            
            рклркХрлНркд рк╡рк┐рк╖ркп ркиркВркмрк░рлЛ ркЖрккрлЛ (comma separated):
            """,
            "image_description": """
            ркЖ ркЧркгрк┐ркдркирк╛ ркЪрк┐ркдрлНрк░ркирлБркВ рк╢рлИркХрлНрк╖ркгрк┐ркХ рк╡рк░рлНркгрки ркЧрлБркЬрк░рк╛ркдрлАркорк╛ркВ ркЖрккрлЛ:
            
            ркЪрк┐ркдрлНрк░ркорк╛ркВ ркЬрлЗ ркжрлЗркЦрк╛ркп ркЫрлЗ: {image_content}
            
            рк╕ркВркжрк░рлНркн: рк╡рк░рлНркЧ 10 ркЧркгрк┐ркд - {context}
            
            ркЧрлБркЬрк░рк╛ркдрлАркорк╛ркВ рк╢рлИркХрлНрк╖ркгрк┐ркХ рк╡рк░рлНркгрки ркЖрккрлЛ (рк╢рлБркВ ркжрлЗркЦрк╛ркп ркЫрлЗ, ркХрлЗрк╡рк╛ ркЙрккркпрлЛркЧ ркорк╛ркЯрлЗ ркЫрлЗ):
            """
        }
    

    def extract_pdf_with_images(self, pdf_path):
        """Extract text and images from PDF with enhanced detection capabilities"""
        print("\n" + "="*50)
        print("ЁЯУД STEP 1: ENHANCED PDF EXTRACTION WITH IMAGES (PAGE BY PAGE)")
        print("="*50)
        print(f"ЁЯУД Processing file: {os.path.basename(pdf_path)}")
        print(f"ЁЯУК API Call Status - Vision: {self.api_calls['vision_api']}, Gemini: {self.api_calls['gemini_api']}")
        
        start_time = time.time()
        
        # Convert PDF to images using pdf2image
        try:
            images = convert_from_path(pdf_path, dpi=300, fmt='png')
            print(f"ЁЯУД Converted {len(images)} pages to images")
        except Exception as e:
            print(f"тЭМ Failed to convert PDF to images: {str(e)[:100]}...")
            return []
        
        pages_data = []
        
        for page_idx, image in enumerate(tqdm(images, desc="Processing pages")):
            # Convert image to bytes
            img_buffer = BytesIO()
            image.save(img_buffer, format="PNG")
            img_base64 = base64.b64encode(img_buffer.getvalue()).decode('utf-8')
            img_buffer.close()
            
            file_size = len(img_base64) / (1024 * 1024)  # MB
            print(f"ЁЯУД Page {page_idx+1} image size: {file_size:.2f} MB")
            
            # ENHANCED: Prepare API request with multiple detection features
            api_url = f"https://vision.googleapis.com/v1/images:annotate?key={self.vision_api_key}"
            
            request_payload = {
                "requests": [
                    {
                        "image": {
                            "content": img_base64
                        },
                        "features": [
                            {
                                "type": "TEXT_DETECTION",
                                "maxResults": 100
                            },
                            {
                                "type": "DOCUMENT_TEXT_DETECTION"  # NEW: Better for structured content
                            },
                            {
                                "type": "OBJECT_LOCALIZATION",
                                "maxResults": 20
                            }
                        ],
                        "imageContext": {
                            "languageHints": ["gu", "en"]  # Gujarati and English
                        }
                    }
                ]
            }
            
            print(f"ЁЯЪА Sending enhanced image request for page {page_idx+1} to Google Vision API...")
            headers = {'Content-Type': 'application/json'}
            response = requests.post(api_url, json=request_payload, headers=headers)
            
            # Count Vision API call
            self.api_calls["vision_api"] += 1
            print(f"ЁЯУК Vision API Call #{self.api_calls['vision_api']} completed for page {page_idx+1}")
            
            if response.status_code != 200:
                print(f"тЭМ Vision API Error for page {page_idx+1}: {response.status_code}")
                print(f"ЁЯФН Error details: {response.text[:200]}...")
                pages_data.append({
                    "page_number": page_idx + 1,
                    "text": "",
                    "images": [],
                    "extracted_at": datetime.now().isoformat(),
                    "error": f"Vision API error: {response.status_code} - {response.text[:200]}"
                })
                continue
            
            result = response.json()
            print(f"ЁЯФН API Response for page {page_idx+1}: {json.dumps(result, ensure_ascii=False, indent=2)[:500]}...")
            
            # ENHANCED: Process response with multiple detection methods
            page_data = self._process_enhanced_vision_response(result, page_idx + 1)
            pages_data.append(page_data)
            time.sleep(1)  # Rate limiting
        
        processing_time = time.time() - start_time
        total_images = sum(len(page.get('images', [])) for page in pages_data)
        total_characters = sum(len(page.get('text', '')) for page in pages_data)
        
        print("\nтЬЕ ENHANCED PDF EXTRACTION COMPLETED")
        print(f"ЁЯУД Pages extracted: {len(pages_data)} / {len(images)}")
        print(f"ЁЯЦ╝я╕П Images/diagrams detected: {total_images}")
        print(f"ЁЯФН Total characters extracted: {total_characters}")
        print(f"тП▒я╕П Processing time: {processing_time:.2f} seconds")
        print(f"ЁЯУК Total Vision API calls so far: {self.api_calls['vision_api']}")
        
        return pages_data

    def _process_enhanced_vision_response(self, result, page_number):
        """Process enhanced Vision API response with multiple detection methods"""
        print(f"ЁЯФН Processing enhanced Vision API response for page {page_number}")
        
        page_data = {
            "page_number": page_number,
            "text": "",
            "images": [],
            "extracted_at": datetime.now().isoformat()
        }
        
        if 'responses' not in result or len(result['responses']) == 0:
            print(f"тЪая╕П No response data for page {page_number}")
            page_data["error"] = "No response data from Vision API"
            return page_data
        
        page_response = result['responses'][0]
        
        # Method 1: Extract text using TEXT_DETECTION (existing)
        if 'textAnnotations' in page_response and page_response['textAnnotations']:
            page_data["text"] = page_response['textAnnotations'][0].get('description', '')
            print(f"ЁЯУД Page {page_number}: {len(page_data['text'])} characters extracted (TEXT_DETECTION)")
        else:
            print(f"тЪая╕П No textAnnotations for page {page_number}")
            page_data["error"] = "No text extracted from TEXT_DETECTION"
        
        # Method 2: Enhanced text extraction using DOCUMENT_TEXT_DETECTION
        if 'fullTextAnnotation' in page_response:
            document_text = page_response['fullTextAnnotation'].get('text', '')
            if len(document_text) > len(page_data["text"]):
                page_data["text"] = document_text
                print(f"ЁЯУД Page {page_number}: Enhanced text extraction - {len(document_text)} characters (DOCUMENT_TEXT_DETECTION)")
        
        # Method 3: Object detection (existing but enhanced)
        detected_objects = []
        if 'localizedObjectAnnotations' in page_response:
            for obj in page_response['localizedObjectAnnotations']:
                print(f"ЁЯЦ╝я╕П Page {page_number}: Detected object '{obj['name']}' (confidence: {obj.get('score', 0):.2f})")
                # Enhanced object type detection
                if self._is_mathematical_content(obj['name']):
                    detected_objects.append({
                        "object_type": obj['name'],
                        "confidence": obj.get('score', 0),
                        "detection_method": "vision_object_detection",
                        "raw_detection": obj['name']
                    })
                    print(f"ЁЯЦ╝я╕П Page {page_number}: Added mathematical object '{obj['name']}' to detection list")
        
        # Store initial detections (will be enhanced by Gemini later)
        page_data["images"] = detected_objects
        
        chapter_name = getattr(self, "current_chapter", "ркЕркЬрлНркЮрк╛ркд ркЕркзрлНркпрк╛ркп")  # You can set before processing
        ai_detected = self.detect_mathematical_content_with_ai(page_data["text"], chapter_name, page_number)

        for det in ai_detected:
            page_data["images"].append({
                "object_type": det,
                "confidence": 1.0,
                "detection_method": "gemini_ai_detection",
                "raw_detection": det
            })
        
        return page_data


    def _is_mathematical_content(self, object_name):
        """Check if detected object is likely mathematical content (English labels from Vision API)"""
        
        # English keywords (from Vision API object detection)
        english_mathematical_keywords = [
            'diagram', 'chart', 'graph', 'table', 'mathematical expression', 
            'formula', 'image', 'figure', 'equation', 'plot', 'grid',
            'coordinate', 'axis', 'line', 'curve', 'geometric', 'triangle',
            'circle', 'rectangle', 'polygon', 'shape', 'drawing', 'illustration'
        ]
        
        # Gujarati keywords (if Vision API occasionally returns Gujarati labels)
        gujarati_mathematical_keywords = [
            'ркЖркХрлГркдрк┐', 'ркЪрк╛рк░рлНркЯ', 'ркЖрк▓рлЗркЦ', 'ркХрлЛрк╖рлНркЯркХ', 'рк╕рлВркдрлНрк░', 'рк╕ркорлАркХрк░ркг',
            'ркдрлНрк░рк┐ркХрлЛркг', 'рк╡рк░рлНркдрлБрк│', 'ркЪркдрлБрк░рлНркнрлБркЬ', 'рк░рлЗркЦрк╛ркХрлГркдрк┐', 'ркЪрк┐ркдрлНрк░'
        ]
        
        object_lower = object_name.lower()
        
        # Check English keywords (primary check)
        for keyword in english_mathematical_keywords:
            if keyword in object_lower:
                print(f"тЬЕ Mathematical content detected (English): '{object_name}' contains '{keyword}'")
                return True
        
        # Check Gujarati keywords (fallback check)
        for keyword in gujarati_mathematical_keywords:
            if keyword in object_name:
                print(f"тЬЕ Mathematical content detected (Gujarati): '{object_name}' contains '{keyword}'")
                return True
        
        print(f"тЭМ Non-mathematical content: '{object_name}'")
        return False


        

    def detect_mathematical_content_with_ai(self, page_text, chapter_name, page_number):
        """Detect and describe mathematical diagrams in Gujarati with chapter-aware hints"""
        
        chapter_content_map = {
        "рк╡рк╛рк╕рлНркдрк╡рк┐ркХ рк╕ркВркЦрлНркпрк╛ркУ": [
            "рк╕ркВркЦрлНркпрк╛ рк░рлЗркЦрк╛ рккрк░ ркжрк░рлНрк╢рк╛рк╡рлЗрк▓рлА рк╕ркВркЦрлНркпрк╛ркУ",
            "ркорлВрк│рк╛ркВркХ рк╕рк╛ркерлЗ рк╕ркВркмркВркзрк┐ркд ркЖркХрлГркдрк┐ркУ"
        ],
        "ркмрк╣рлБрккркжрлАркУ": [
            "ркмрк╣рлБрккркжрлАркУркирк╛ ркЧрлНрк░рк╛ркл",
            "ркорлВрк│ ркЕркирлЗ ркЧрлБркгрк╛ркХрк╛рк░ ркжрк░рлНрк╢рк╛рк╡ркдрлА ркЖркХрлГркдрк┐ркУ"
        ],
        "ркжрлНрк╡рк┐ркЪрк▓ рк╕рлБрк░рлЗркЦ рк╕ркорлАркХрк░ркгркпрлБркЧрлНрко": [
            "рк╕ркорлАркХрк░ркгркирк╛ ркЧрлНрк░рк╛ркл",
            "ркХрлЛрк╖рлНркЯркХ",
            "рк░рлЗркЦрк╛ркУркирк╛ intersection"
        ],
        "ркжрлНрк╡рк┐ркШрк╛ркд рк╕ркорлАркХрк░ркг": [
            "рккрлЗрк░рк╛ркмрлЛрк▓рк╛ркирлЛ ркЧрлНрк░рк╛ркл",
            "рк╡рк┐ркнрк┐ркирлНрки ркХрлЗрк╕ ркорк╛ркЯрлЗркирк╛ ркЧрлНрк░рк╛ркл (рк╡рк╛рк╕рлНркдрк╡рк┐ркХ ркорлВрк│, ркХрк▓рлНрккрк┐ркд ркорлВрк│)",
            "рк╡рк░рлНркЯрлЗркХрлНрк╕ ркжрк░рлНрк╢рк╛рк╡ркдрлЛ ркЧрлНрк░рк╛ркл"
        ],
        "рк╕ркорк╛ркирлНркдрк░ рк╢рлНрк░рлЗркгрлА": [
            "ркЕркирлБркХрлНрк░рко ркжрк░рлНрк╢рк╛рк╡ркдрлА ркХрлЛрк╖рлНркЯркХ",
            "ркЖркирлБркХрлНрк░ркорк┐ркХ рк╕ркВркЦрлНркпрк╛ркУ ркжрк░рлНрк╢рк╛рк╡ркдрлЛ ркЖрк▓рлЗркЦ"
        ],
        "ркдрлНрк░рк┐ркХрлЛркг": [
            "ркдрлНрк░рк┐ркХрлЛркгркирлА рк░ркЪркирк╛",
            "рк╕ркорк╛ркиркдрк╛ ркжрк░рлНрк╢рк╛рк╡ркдрлА ркЖркХрлГркдрк┐ркУ",
            "рккрлНрк░ркорк╛ркг ркжрк░рлНрк╢рк╛рк╡ркдрлА ркЖркХрлГркдрк┐ркУ"
        ],
        "ркпрк╛рко ркнрлВркорк┐ркдрк┐": [
            "ркЕркХрлНрк╖рк╛ркВркХрлЛ рккрк░ркирк╛ ркмрк┐ркВркжрлБркУ",
            "ркЕркВркдрк░ рк╕рлВркдрлНрк░",
            "рк╡рк┐ркнрк╛ркЧ рк╕рлВркдрлНрк░",
            "ркдрлНрк░рк┐ркХрлЛркгркирлБркВ ркХрлНрк╖рлЗркдрлНрк░рклрк│ ркжрк░рлНрк╢рк╛рк╡ркдрлА ркЖркХрлГркдрк┐"
        ],
        "ркдрлНрк░рк┐ркХрлЛркгркорк┐ркдрк┐ ркирлЛ рккрк░рк┐ркЪркп": [
            "рк╕ркоркХрлЛркг ркдрлНрк░рк┐ркХрлЛркгркорк╛ркВ ркдрлНрк░рк┐ркХрлЛркгркорк┐ркдрлАркп ркЧрлБркгрлЛркдрлНркдрк░",
            "ркпрлВркирк┐ркЯ рк╕рк░рлНркХрк▓"
        ],
        "ркдрлНрк░рк┐ркХрлЛркгркорк┐ркдрк┐ ркирк╛ ркЙрккркпрлЛркЧрлЛ": [
            "ркКркВркЪрк╛ркИ ркЕркирлЗ ркЕркВркдрк░ ркжрк░рлНрк╢рк╛рк╡ркдрлА ркЖркХрлГркдрк┐ркУ",
            "ркХрлЛркг ркЙркирлНркиркдрк┐ ркЕркирлЗ ркЕрк╡ркирлАркдрк┐"
        ],
        "рк╡рк░рлНркдрлБрк│": [
            "рк╡рк░рлНркдрлБрк│",
            "рк╕рлНрккрк░рлНрк╢ркХ",
            "ркЬрлНркпрлЛркдрк┐",
            "ркдрлНрк░ркЬрлНркпрк╛"
        ],
        "рк░ркЪркирк╛": [
            "ркХркВрккрк╛рк╕ркерлА рк░ркЪркирк╛",
            "ркХрлЛркг ркжрлНрк╡рк┐ркнрк╛ркЬркХ",
            "ркдрлНрк░рк┐ркХрлЛркгркирлА рк░ркЪркирк╛"
        ],
        "рк╡рк░рлНркдрлБрк│ рк╕ркВркмркВркзрк┐ркд ркХрлНрк╖рлЗркдрлНрк░рклрк│": [
            "рк╡рк░рлНркдрлБрк│ркирлЛ ркХрлНрк╖рлЗркдрлНрк░рклрк│",
            "рк╕рлЗркХрлНркЯрк░",
            "рк╕рлЗркЧркорлЗркирлНркЯ"
        ],
        "рккрлГрк╖рлНркарклрк│ ркЕркирлЗ ркШркирклрк│": [
            "ркШркирк╛ркХрлГркдрк┐ркУркирк╛ ркЖрк▓рлЗркЦ",
            "рк╕рк┐рк▓рк┐ркирлНркбрк░",
            "рк╢ркВркХрлБ",
            "ркЧрлЛрк│рк╛ркХрк╛рк░"
        ],
        "ркЖркВркХркбрк╛рк╢рк╛рк╕рлНркдрлНрк░": [
            "рк╣рк┐рк╕рлНркЯрлЛркЧрлНрк░рк╛рко",
            "ркмрк╛рк░ ркЪрк╛рк░рлНркЯ",
            "ркЖрк╡рк░рлНркдрки ркХрлЛрк╖рлНркЯркХ",
            "рккрк╛ркИ ркЪрк╛рк░рлНркЯ"
        ],
        "рк╕ркВркнрк╛рк╡ркирк╛": [
            "рк╕ркВркнрк╛рк╡ркирк╛ рк╡рлГркХрлНрк╖",
            "рккрлНрк░ркпрлЛркЧрлЛркирк╛ ркЖркХрлГркдрк┐ркУ",
            "ркиркорлВркирк╛ рк╕рлНркерк╛рки"
            ]
        }
        
        expected_content = chapter_content_map.get(chapter_name, [])
        
        prompt = f"""
        ркдркорлЗ ркзрлЛрк░ркг 10 ркЧркгрк┐ркдркирк╛ рккрк╛ркарлНркпрккрлБрк╕рлНркдркХркирк╛ ркЕркзрлНркпрк╛ркп "{chapter_name}" ркирлБркВ рккрк╛ркирлБркВ {page_number} рк╡рк╛ркВркЪрлА рк░рк╣рлНркпрк╛ ркЫрлЛ. 

        ркЖ ркЕркзрлНркпрк╛ркпркорк╛ркВ рк╕рк╛ркорк╛ркирлНркп рк░рлАркдрлЗ ркЬрлЛрк╡рк╛ ркорк│ркдрлА ркЖркХрлГркдрк┐ркУ: {', '.join(expected_content)}.

        ркирлАркЪрлЗркирк╛ рк▓ркЦрк╛ркгркирлЗ ркЖркзрк╛рк░рлЗ ркУрк│ркЦрлЛ ркХрлЗ ркЖ рккрк╛ркирк╛ркорк╛ркВ ркХркИ ркЖркХрлГркдрк┐ркУ ркЫрлЗ. 
        ркжрк░рлЗркХ ркорк╛ркЯрлЗ рк╕рлНрккрк╖рлНркЯ ркЧрлБркЬрк░рк╛ркдрлА рк╡рк░рлНркгрки ркЕркирлЗ рк╢рлИркХрлНрк╖ркгрк┐ркХ рк╣рлЗркдрлБ ркЖрккрлЛ.

        рк▓ркЦрк╛ркг:
        {page_text}

        рклркХрлНркд ркЖ рклрлЛрк░рлНркорлЗркЯркорк╛ркВ JSON return ркХрк░рлЛ (ркХрлЛркИ рк╡ркзрк╛рк░рк╛ркирлЛ рк▓ркЦрк╛ркг ркирк╣рлАркВ):
        [
        {{
            "description": "x + y = 5 ркирлБркВ рк╕рлБрк░рлЗркЦ рк╕ркорлАркХрк░ркг ркжрк░рлНрк╢рк╛рк╡ркдрлЛ ркЧрлНрк░рк╛ркл ркЬрлЗркорк╛ркВ рк░рлЗркЦрк╛ (0,5) ркЕркирлЗ (5,0) рккрк░ркерлА рккрк╕рк╛рк░ ркерк╛ркп ркЫрлЗ.",
            "educational_context": "рк╡рк┐ркжрлНркпрк╛рк░рлНркерлАркУ рк╕ркорлАркХрк░ркгркирлЗ ркЧрлНрк░рк╛рклрк┐ркХ рк░рлАркдрлЗ ркХрлЗрк╡рлА рк░рлАркдрлЗ рк░ркЬрлВ ркерк╛ркп ркЫрлЗ ркдрлЗ рк╕ркоркЬрлА рк╢ркХрлЗ ркЫрлЗ."
        }}
        ]
        ркЬрлЛ ркЖркХрлГркдрк┐ рки рк╣рлЛркп ркдрлЛ ркЦрк╛рк▓рлА array [] return ркХрк░рлЛ.
        """
        
        response = self.gemini_model.generate_content(prompt)
        text = response.text.strip()
        
        # ЁЯЫая╕П Clean out markdown fences if Gemini adds them
        if text.startswith("```"):
            text = text.strip("`")
            if text.lower().startswith("json"):
                text = text[4:].strip()
        
        try:
            detections = json.loads(text)
            return detections if isinstance(detections, list) else []
        except Exception:
            print(f"тЪая╕П Gemini response parsing error (cleaned): {text[:200]}")
            return []

  
    def describe_images_with_ai(self, pages_data):
        """Generate educational descriptions for detected images using Gemini API"""
        print("\n" + "="*50)
        print("ЁЯЦ╝я╕П STEP 2: IMAGE DESCRIPTION GENERATION")
        print("="*50)
        
        total_images = sum(len(page.get('images', [])) for page in pages_data)
        print(f"ЁЯЦ╝я╕П Total images to describe: {total_images}")
        print(f"ЁЯУК Current API calls - Vision: {self.api_calls['vision_api']}, Gemini: {self.api_calls['gemini_api']}")
        
        if total_images == 0:
            print("тД╣я╕П No images detected. Skipping image description step.")
            return pages_data
        
        start_time = time.time()
        successful_descriptions = 0
        failed_descriptions = 0
        
        for page in tqdm(pages_data, desc="Describing images"):
            if not page.get("images"):
                print(f"ЁЯУД Page {page['page_number']}: No images to describe")
                continue
            
            print(f"ЁЯУД Page {page['page_number']}: Processing {len(page['images'])} images")
            for image in page["images"]:
                try:
                    object_type = image["object_type"]
                    confidence = image["confidence"]
                    context = f"Page {page['page_number']} of Class 10 Mathematics textbook"
                    
                    prompt = self.prompts["image_description"].format(
                        image_content=f"{object_type} (confidence: {confidence:.2f})",
                        context=context
                    )
                    
                    print(f"  ЁЯФД Sending image description request for {object_type} to Gemini API...")
                    response = self.gemini_model.generate_content(prompt)
                    
                    self.api_calls["gemini_api"] += 1
                    successful_descriptions += 1
                    
                    image["educational_description"] = response.text
                    print(f"  тЬЕ Description generated for {object_type} ({len(response.text)} characters)")
                    
                    time.sleep(1)
                except Exception as e:
                    failed_descriptions += 1
                    print(f"  тЭМ Error describing {object_type}: {str(e)[:100]}...")
                    image["educational_description"] = "рк╡рк░рлНркгрки ркЙрккрк▓ркмрлНркз ркиркерлА"
        
        processing_time = time.time() - start_time
        
        print("\nтЬЕ IMAGE DESCRIPTION COMPLETED")
        print(f"ЁЯЦ╝я╕П Successful descriptions: {successful_descriptions}")
        print(f"тЭМ Failed descriptions: {failed_descriptions}")
        print(f"тП▒я╕П Processing time: {processing_time:.2f} seconds")
        print(f"ЁЯУК Gemini API calls for descriptions: {successful_descriptions}")
        print(f"ЁЯУК Total Gemini API calls so far: {self.api_calls['gemini_api']}")
        
        return pages_data
    
    def integrate_images_in_text(self, pages_data):
        """Integrate image references into page text"""
        print("\n" + "="*50)
        print("ЁЯФЧ STEP 3: TEXT-IMAGE INTEGRATION")
        print("="*50)
        
        total_pages_with_images = sum(1 for page in pages_data if page.get("images"))
        total_image_refs = sum(len(page.get("images", [])) for page in pages_data)
        
        print(f"ЁЯУД Pages with images: {total_pages_with_images}")
        print(f"ЁЯФЧ Image references to add: {total_image_refs}")
        
        if total_image_refs == 0:
            print("тД╣я╕П No images to integrate. Skipping integration step.")
            return pages_data
        
        start_time = time.time()
        integrated_count = 0
        
        for page in pages_data:
            if page["images"]:
                print(f"ЁЯУД Page {page['page_number']}: Integrating {len(page['images'])} image references")
                
                image_refs = []
                for i, image in enumerate(page["images"], 1):
                    ref_text = f"\n[ркЪрк┐ркдрлНрк░ {i}: {image['educational_description']}]"
                    image_refs.append(ref_text)
                    integrated_count += 1
                
                original_length = len(page["text"])
                page["text"] += "".join(image_refs)
                new_length = len(page["text"])
                
                print(f"  тЬЕ Added {len(image_refs)} references (+{new_length - original_length} characters)")
                
                for i, image in enumerate(page["images"], 1):
                    image["reference_id"] = f"ркЪрк┐ркдрлНрк░_{page['page_number']}_{i}"
        
        processing_time = time.time() - start_time
        
        print("\nтЬЕ TEXT-IMAGE INTEGRATION COMPLETED")
        print(f"ЁЯФЧ Total image references integrated: {integrated_count}")
        print(f"тП▒я╕П Processing time: {processing_time:.2f} seconds")
        print("ЁЯУК No API calls required for this step")
        
        return pages_data
    
    def summarize_pages(self, pages_data):
        """Summarize each page using Gemini with image context"""
        print("\n" + "="*50)
        print("ЁЯУЭ STEP 4: PAGE-WISE SUMMARIZATION")
        print("="*50)
        
        print(f"ЁЯУД Total pages to summarize: {len(pages_data)}")
        print(f"ЁЯУК Current API calls - Vision: {self.api_calls['vision_api']}, Gemini: {self.api_calls['gemini_api']}")
        
        start_time = time.time()
        successful_summaries = 0
        failed_summaries = 0
        
        for page in tqdm(pages_data, desc="ЁЯУЭ Summarizing pages"):
            try:
                print(f"\nЁЯУД Processing Page {page['page_number']}")
                
                image_descriptions = ""
                if page["images"]:
                    descriptions = [img["educational_description"] for img in page["images"]]
                    image_descriptions = "\n".join(descriptions)
                    print(f"  ЁЯЦ╝я╕П Including {len(page['images'])} image descriptions")
                else:
                    image_descriptions = "ркЖ рккрк╛ркирк╛ркорк╛ркВ ркХрлЛркИ ркЪрк┐ркдрлНрк░ ркиркерлА."
                    print("  ЁЯУД No images on this page")
                
                text_length = len(page["text"])
                print(f"  ЁЯУК Text length: {text_length} characters")
                
                prompt = self.prompts["page_summarization"].format(
                    page_text=page["text"],
                    image_descriptions=image_descriptions
                )
                
                print(f"  ЁЯФД Sending to Gemini API...")
                response = self.gemini_model.generate_content(prompt)
                
                self.api_calls["gemini_api"] += 1
                successful_summaries += 1
                
                page["page_summary"] = response.text
                page["summarized_at"] = datetime.now().isoformat()
                
                summary_length = len(response.text)
                print(f"  тЬЕ Summary generated ({summary_length} characters) - API call #{self.api_calls['gemini_api']}")
                
                time.sleep(1)
            except Exception as e:
                failed_summaries += 1
                print(f"  тЭМ Error: {str(e)[:100]}...")
                page["page_summary"] = "рк╕рк╛рк░рк╛ркВрк╢ ркЙрккрк▓ркмрлНркз ркиркерлА"
        
        processing_time = time.time() - start_time
        
        print("\nтЬЕ PAGE SUMMARIZATION COMPLETED")
        print(f"ЁЯУЭ Successful summaries: {successful_summaries}")
        print(f"тЭМ Failed summaries: {failed_summaries}")
        print(f"тП▒я╕П Processing time: {processing_time:.2f} seconds")
        print(f"ЁЯУК Gemini API calls for summaries: {successful_summaries}")
        print(f"ЁЯУК Total Gemini API calls so far: {self.api_calls['gemini_api']}")
        
        return pages_data
    
    def analyze_chapter(self, pages_data):
        """Generate chapter analysis from all page summaries"""
        print("\n" + "="*50)
        print("ЁЯУЪ STEP 5: CHAPTER ANALYSIS")
        print("="*50)
        
        page_summaries = []
        valid_summaries = 0
        
        for page in pages_data:
            if 'page_summary' in page and page['page_summary'] != "рк╕рк╛рк░рк╛ркВрк╢ ркЙрккрк▓ркмрлНркз ркиркерлА":
                page_summaries.append(f"рккрк╛ркирлБркВ {page['page_number']}: {page['page_summary']}")
                valid_summaries += 1
        
        print(f"ЁЯУД Valid page summaries: {valid_summaries}/{len(pages_data)}")
        print(f"ЁЯУК Current API calls - Vision: {self.api_calls['vision_api']}, Gemini: {self.api_calls['gemini_api']}")
        
        if not page_summaries:
            print("тЭМ No valid page summaries found. Cannot analyze chapter.")
            return {"chapter_summary": "ркЕркзрлНркпрк╛ркп рк╡рк┐рк╢рлНрк▓рлЗрк╖ркгркорк╛ркВ ркнрлВрк▓ - ркХрлЛркИ рк╕рк╛рк░рк╛ркВрк╢ ркЙрккрк▓ркмрлНркз ркиркерлА", "analyzed_at": datetime.now().isoformat()}
        
        summaries_text = "\n\n".join(page_summaries)
        total_chars = len(summaries_text)
        print(f"ЁЯУК Total summary text: {total_chars} characters")
        
        start_time = time.time()
        
        try:
            print("ЁЯФД Sending chapter analysis request to Gemini API...")
            
            prompt = self.prompts["chapter_analysis"].format(
                page_summaries=summaries_text
            )
            
            response = self.gemini_model.generate_content(prompt)
            self.api_calls["gemini_api"] += 1
            
            analysis_text = response.text
            analysis_length = len(analysis_text)
            
            processing_time = time.time() - start_time
            
            print(f"тЬЕ Chapter analysis completed ({analysis_length} characters)")
            print(f"тП▒я╕П Processing time: {processing_time:.2f} seconds")
            print(f"ЁЯУК API call #{self.api_calls['gemini_api']} - Chapter Analysis")
            print(f"ЁЯУК Total Gemini API calls so far: {self.api_calls['gemini_api']}")
            
            return {
                "chapter_summary": analysis_text,
                "analyzed_at": datetime.now().isoformat()
            }
        except Exception as e:
            processing_time = time.time() - start_time
            print(f"тЭМ Error in chapter analysis: {str(e)[:100]}...")
            print(f"тП▒я╕П Failed after: {processing_time:.2f} seconds")
            
            return {
                "chapter_summary": "ркЕркзрлНркпрк╛ркп рк╡рк┐рк╢рлНрк▓рлЗрк╖ркгркорк╛ркВ ркнрлВрк▓",
                "analyzed_at": datetime.now().isoformat()
            }
    
    def extract_topics_from_analysis(self, chapter_info):
        """Extract topics list from chapter analysis"""
        print("\n" + "="*50)
        print("ЁЯУЛ STEP 6: TOPIC EXTRACTION")
        print("="*50)
        
        analysis = chapter_info["chapter_summary"]
        print(f"ЁЯУК Analyzing {len(analysis)} characters of chapter summary")
        
        topics = []
        lines = analysis.split('\n')
        
        print("ЁЯФН Searching for topics in chapter analysis...")
        
        for line in lines:
            line = line.strip()
            if line and (line[0].isdigit() or line.startswith('- ')):
                topic = line.lstrip('0123456789.- ').strip()
                if topic and len(topic) > 5:
                    topics.append(topic)
                    print(f"  тЬЕ Topic {len(topics)}: {topic[:50]}...")
        
        print(f"\nЁЯУЛ TOPIC EXTRACTION COMPLETED")
        print(f"ЁЯОп Topics extracted: {len(topics)}")
        
        if len(topics) == 0:
            print("тЪая╕П No topics found in chapter analysis. Creating default topics...")
            topics = ["рк╕рк╛ркорк╛ркирлНркп ркЧркгрк┐ркдрлАркп рк╕ркВркХрк▓рлНрккркирк╛ркУ", "рк╕рлВркдрлНрк░рлЛ ркЕркирлЗ ркЧркгркдрк░рлА", "ркЙркжрк╛рк╣рк░ркгрлЛ ркЕркирлЗ ркХрк╕рлЛркЯрлАркУ"]
        
        print("ЁЯУК No API calls required for topic extraction")
        
        print("\nЁЯУЛ EXTRACTED TOPICS:")
        for i, topic in enumerate(topics, 1):
            print(f"  {i}. {topic}")
        
        return topics
    
    def assign_topics_to_pages(self, pages_data, topics_list):
        """Assign non-overlapping topics to each page"""
        print("\n" + "="*50)
        print("ЁЯП╖я╕П STEP 7: TOPIC ASSIGNMENT")
        print("="*50)
        
        print(f"ЁЯУД Pages to process: {len(pages_data)}")
        print(f"ЁЯОп Available topics: {len(topics_list)}")
        print(f"ЁЯУК Current API calls - Vision: {self.api_calls['vision_api']}, Gemini: {self.api_calls['gemini_api']}")
        
        topics_with_numbers = []
        for i, topic in enumerate(topics_list, 1):
            topics_with_numbers.append(f"{i}. {topic}")
        
        topics_string = "\n".join(topics_with_numbers)
        print(f"ЁЯУЛ Topics formatted for AI assignment")
        
        start_time = time.time()
        successful_assignments = 0
        failed_assignments = 0
        total_topic_assignments = 0
        
        for page in tqdm(pages_data, desc="ЁЯП╖я╕П Assigning topics"):
            try:
                print(f"\nЁЯУД Processing Page {page['page_number']}")
                
                text_length = len(page["text"])
                text_sample = page["text"][:2000]
                
                print(f"  ЁЯУК Text length: {text_length} characters (using first 2000)")
                
                prompt = self.prompts["topic_assignment"].format(
                    page_text=text_sample,
                    topics_list=topics_string
                )
                
                print(f"  ЁЯФД Sending to Gemini API...")
                response = self.gemini_model.generate_content(prompt)
                
                self.api_calls["gemini_api"] += 1
                successful_assignments += 1
                
                topic_numbers = []
                response_text = response.text.strip()
                
                print(f"  ЁЯУЭ AI Response: {response_text[:50]}...")
                
                for part in response_text.split(','):
                    try:
                        num = int(part.strip())
                        if 1 <= num <= len(topics_list) and num not in topic_numbers:
                            topic_numbers.append(num)
                    except ValueError:
                        continue
                
                page["assigned_topics"] = topic_numbers
                page["topics_assigned_at"] = datetime.now().isoformat()
                
                total_topic_assignments += len(topic_numbers)
                print(f"  тЬЕ Assigned {len(topic_numbers)} topics: {topic_numbers} - API call #{self.api_calls['gemini_api']}")
                
                time.sleep(1)
            except Exception as e:
                failed_assignments += 1
                print(f"  тЭМ Error: {str(e)[:100]}...")
                page["assigned_topics"] = []
        
        processing_time = time.time() - start_time
        avg_topics_per_page = total_topic_assignments / len(pages_data) if pages_data else 0
        
        print("\nтЬЕ TOPIC ASSIGNMENT COMPLETED")
        print(f"ЁЯУД Successful assignments: {successful_assignments}")
        print(f"тЭМ Failed assignments: {failed_assignments}")
        print(f"ЁЯОп Total topic assignments: {total_topic_assignments}")
        print(f"ЁЯУК Average topics per page: {avg_topics_per_page:.1f}")
        print(f"тП▒я╕П Processing time: {processing_time:.2f} seconds")
        print(f"ЁЯУК Gemini API calls for topic assignment: {successful_assignments}")
        print(f"ЁЯУК Total Gemini API calls so far: {self.api_calls['gemini_api']}")
        
        return pages_data
    
    def save_results(self, pdf_path, pages_data, chapter_info, topics_list):
        """Save all results to single JSON file"""
        print("\n" + "="*50)
        print("ЁЯТ╛ STEP 8: SAVE RESULTS")
        print("="*50)
        
        processing_end_time = datetime.now()
        total_processing_time = (processing_end_time - self.api_calls["start_time"]).total_seconds()
        
        total_images = sum(len(page.get('images', [])) for page in pages_data)
        total_characters = sum(len(page.get('text', '')) for page in pages_data)
        total_topic_assignments = sum(len(page.get('assigned_topics', [])) for page in pages_data)
        
        print(f"ЁЯУК FINAL PROCESSING STATISTICS:")
        print(f"  ЁЯУД Total pages: {len(pages_data)}")
        print(f"  ЁЯЦ╝я╕П Total images: {total_images}")
        print(f"  ЁЯУЭ Total characters extracted: {total_characters:,}")
        print(f"  ЁЯОп Total topics extracted: {len(topics_list)}")
        print(f"  ЁЯП╖я╕П Total topic assignments: {total_topic_assignments}")
        print(f"  тП▒я╕П Total processing time: {total_processing_time:.2f} seconds")
        
        output_data = {
            "metadata": {
                "source_pdf": os.path.basename(pdf_path),
                "board": "GSEB",
                "class": 10,
                "subject": "Mathematics",
                "medium": "Gujarati",
                "processed_at": processing_end_time.isoformat(),
                "total_pages": len(pages_data),
                "total_topics": len(topics_list),
                "total_images": total_images,
                "total_characters": total_characters,
                "processing_time_seconds": round(total_processing_time, 2),
                "api_usage": {
                    "vision_api_calls": self.api_calls["vision_api"],
                    "gemini_api_calls": self.api_calls["gemini_api"],
                    "total_api_calls": self.api_calls["vision_api"] + self.api_calls["gemini_api"]
                }
            },
            "chapter_info": {
                **chapter_info,
                "extracted_topics": topics_list
            },
            "pages": pages_data
        }
        
        base_name = os.path.splitext(os.path.basename(pdf_path))[0]
        timestamp = processing_end_time.strftime("%Y%m%d_%H%M%S")
        output_filename = f"gseb_class10_maths_{base_name}_{timestamp}.json"
        
        print(f"ЁЯУБ Saving to file: {output_filename}")
        
        try:
            with open(output_filename, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            file_size = os.path.getsize(output_filename) / (1024 * 1024)
            
            print(f"тЬЕ SAVE COMPLETED")
            print(f"ЁЯТ╛ File size: {file_size:.2f} MB")
            print(f"ЁЯУК API USAGE SUMMARY:")
            print(f"  ЁЯФН Google Vision API calls: {self.api_calls['vision_api']}")
            print(f"  ЁЯза Google Gemini API calls: {self.api_calls['gemini_api']}")
            print(f"  ЁЯУК Total API calls: {self.api_calls['vision_api'] + self.api_calls['gemini_api']}")
            
            return output_filename
        except Exception as e:
            print(f"тЭМ Error saving file: {str(e)}")
            return None
    
    def process_pdf(self, pdf_path):
        """Main processing pipeline with comprehensive logging and API counting"""
        print("\n" + "="*70)
        print("ЁЯЪА GSEB PDF PROCESSING PIPELINE STARTED")
        print("="*70)
        print(f"ЁЯУД File: {os.path.basename(pdf_path)}")
        print(f"ЁЯУЪ Target: Class 10 Mathematics (Gujarati Medium)")
        print(f"ЁЯХР Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ЁЯУК Initial API counters - Vision: 0, Gemini: 0")
        
        try:
            # Step 1: Extract PDF pages with images
            pages_data = self.extract_pdf_with_images(pdf_path)
            
            if not pages_data:
                print("\nтЭМ PIPELINE FAILED: No pages extracted")
                return None
            
            # Step 2: Generate AI descriptions for images/diagrams
            pages_data = self.describe_images_with_ai(pages_data)
            
            # Step 3: Integrate image references into text
            pages_data = self.integrate_images_in_text(pages_data)
            
            # Step 4: Summarize each page (with image context)
            pages_data = self.summarize_pages(pages_data)
            
            # Step 5: Analyze complete chapter
            chapter_info = self.analyze_chapter(pages_data)
            
            # Step 6: Extract topics from analysis
            topics_list = self.extract_topics_from_analysis(chapter_info)
            
            # Step 7: Assign topics to pages
            pages_data = self.assign_topics_to_pages(pages_data, topics_list)
            
            # Step 8: Save complete results
            output_file = self.save_results(pdf_path, pages_data, chapter_info, topics_list)
            
            if not output_file:
                print("\nтЭМ PIPELINE FAILED: Could not save results")
                return None
            
            total_images = sum(len(page.get('images', [])) for page in pages_data)
            total_characters = sum(len(page.get('text', '')) for page in pages_data)
            
            try:
                total_processing_time = (datetime.now() - self.api_calls["start_time"]).total_seconds()
                vision_calls = self.api_calls['vision_api']
                gemini_calls = self.api_calls['gemini_api']
            except (AttributeError, KeyError):
                total_processing_time = 0
                vision_calls = 0
                gemini_calls = 0
            
            print("\n" + "="*70)
            print("ЁЯОЙ PIPELINE COMPLETED SUCCESSFULLY!")
            print("="*70)
            print(f"ЁЯУК FINAL STATISTICS:")
            print(f"  ЁЯУД Pages processed: {len(pages_data)}")
            print(f"  ЁЯЦ╝я╕П Images processed: {total_images}")
            print(f"  ЁЯУЭ Characters extracted: {total_characters:,}")
            print(f"  ЁЯОп Topics extracted: {len(topics_list)}")
            if total_processing_time > 0:
                print(f"  тП▒я╕П Total processing time: {total_processing_time:.2f} seconds")
            print(f"ЁЯУК API USAGE:")
            print(f"  ЁЯФН Google Vision API calls: {vision_calls}")
            print(f"  ЁЯза Google Gemini API calls: {gemini_calls}")
            print(f"  ЁЯУК Total API calls: {vision_calls + gemini_calls}")
            print(f"ЁЯТ╛ Output file: {output_file}")
            print("="*70)
            
            return output_file
        except Exception as e:
            try:
                total_processing_time = (datetime.now() - self.api_calls["start_time"]).total_seconds()
                vision_calls = self.api_calls['vision_api']
                gemini_calls = self.api_calls['gemini_api']
            except (AttributeError, KeyError):
                total_processing_time = 0
                vision_calls = 0
                gemini_calls = 0
            
            print("\n" + "="*70)
            print("тЭМ PIPELINE FAILED!")
            print("="*70)
            print(f"ЁЯЪл Error: {str(e)}")
            if total_processing_time > 0:
                print(f"тП▒я╕П Failed after: {total_processing_time:.2f} seconds")
            print(f"ЁЯУК API calls made before failure:")
            print(f"  ЁЯФН Google Vision API: {vision_calls}")
            print(f"  ЁЯза Google Gemini API: {gemini_calls}")
            print("="*70)
            
            return None

def main():
    """Main execution function"""
    print("ЁЯУЪ GSEB Question Paper Generation System")
    print("ЁЯФз PDF Processing Module - Class 10 Maths (Gujarati)")
    print("тЬи With Image Recognition & Educational Descriptions")
    print("=" * 70)
    
    # Initialize processor
    try:
        processor = GSEBPDFProcessor()
        
    except ValueError as e:
        print(f"тЭМ Initialization Error: {str(e)}")
        print("Please check your .env file and API keys.")
        return
    
    # Get PDF file path from user
    pdf_path = input("\nЁЯУБ Enter the path to your Class 10 Maths Gujarati PDF: ").strip()
    
    if not os.path.exists(pdf_path):
        print("тЭМ File not found! Please check the path.")
        return
    
    processor.current_chapter = "ркжрлНрк╡рк┐ркЪрк▓ рк╕рлБрк░рлЗркЦ рк╕ркорлАркХрк░ркгркпрлБркЧрлНрко"
    # Process the PDF
    result = processor.process_pdf(pdf_path)
    
    if result:
        print(f"\nтЬЕ SUCCESS! Check the output file: {result}")
        print("\nЁЯУЦ The file contains:")
        print("   тАв Page-by-page text extraction")  
        print("   тАв Educational image descriptions")
        print("   тАв Comprehensive page summaries")
        print("   тАв Complete chapter analysis")
        print("   тАв Topic extraction and assignment")
    else:
        print("\nтЭМ Processing failed! Check the error messages above.")

if __name__ == "__main__":
    main()