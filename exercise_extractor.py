# exercise_extractor.py
import os
import json
import time
from datetime import datetime
import google.generativeai as genai
from dotenv import load_dotenv
from tqdm import tqdm

class GSEBExerciseExtractor:
    """
    Extract exercise questions from GSEB Mathematics textbook pages.
    Works for all mathematics chapters - algebra, geometry, trigonometry, statistics, etc.
    
    Features:
    - Detects exercise sections (àª¸à«àªµàª¾àª§à«àª¯àª¾àª¯, àª…àª­à«àª¯àª¾àª¸, àªªà«àª°àª¶à«àª¨à«‹)
    - Splits sub-questions into individual questions
    - Classifies into 9 question types using AI
    - Extracts visual references (àª†àª•à«ƒàª¤àª¿, àª†àª²à«‡àª–, àª•à«‹àª·à«àªŸàª•)
    - Generates answers and explanations
    """
    
    def __init__(self):
        """Initialize the exercise extractor with Gemini API setup"""
        # Load environment variables
        load_dotenv()
        
        # Initialize Gemini AI
        gemini_api_key = os.getenv('GEMINI_API_KEY')
        if not gemini_api_key:
            raise ValueError("GEMINI_API_KEY not found in environment variables")
            
        genai.configure(api_key=gemini_api_key)
        self.gemini_model = genai.GenerativeModel('gemini-2.0-flash')
        
        # Track API usage for cost monitoring
        self.api_calls = {"gemini_api": 0}
        
        # Define question types for validation
        self.valid_question_types = [
            "Very Short / Objective (O)",
            "MCQs (Multiple Choice Questions)",
            "True / False",
            "Fill in the Blanks", 
            "Short Answer â€“ I (SA-I)",
            "Short Answer â€“ II (SA-II)",
            "Long Answer (LA)",
            "Match the Values / (Jodka Jodo)",
            "Diagram-Based"
        ]
        
        print("ğŸ“š Initialized GSEB Exercise Extractor")
        print(f"ğŸ”‘ Gemini API Key: {'âœ… Loaded' if gemini_api_key else 'âŒ Missing'}")
        print(f"ğŸ¯ Target Subject: Mathematics (All Chapters)")

    def load_processed_json(self, json_file_path):
        """
        Load processed JSON from main.py output
        
        Args:
            json_file_path (str): Path to the processed chapter JSON file
            
        Returns:
            dict: Loaded JSON data with pages and metadata
        """
        print(f"\nğŸ“‚ Loading processed JSON: {json_file_path}")
        
        with open(json_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"ğŸ“Š Loaded data:")
        print(f"  ğŸ“„ Total pages: {len(data.get('pages', []))}")
        print(f"  ğŸ“š Chapter: {data.get('metadata', {}).get('source_pdf', 'Unknown')}")
        
        return data

    def extract_exercises_from_chapter(self, json_data):
        """
        Main method to extract exercises from all pages of a mathematics chapter
        
        Args:
            json_data (dict): Processed chapter data with page-by-page text
            
        Returns:
            list: List of extracted exercise questions with metadata
        """
        print("\n" + "="*50)
        print("ğŸ” EXERCISE EXTRACTION FROM MATHEMATICS CHAPTER")
        print("="*50)
        
        pages_data = json_data.get('pages', [])
        chapter_name = self._get_chapter_name(json_data)
        
        all_exercises = []
        
        # Process each page looking for exercise sections
        for page in tqdm(pages_data, desc="ğŸ” Processing pages for exercises"):
            try:
                page_number = page.get('page_number', 0)
                page_text = page.get('text', '')
                
                # Skip pages with insufficient content
                if len(page_text) < 100:
                    print(f"    â­ï¸  Page {page_number}: Insufficient content, skipping")
                    continue
                    
                # # Check for exercise indicators in the page
                # if not self._has_exercise_content(page_text):
                #     continue
                
                print(f"    ğŸ¯ Page {page_number}: Exercise content detected")
                
                # Step 1: Extract exercises using AI
                exercises = self._extract_exercises_with_ai(page_text, chapter_name, page_number)
                
                if exercises:
                    # Step 2: Enhance with visual descriptions from page images
                    exercises = self._enhance_exercises_with_visual_content(exercises, page)
                    
                    # Log extraction results
                    for exercise in exercises:
                        qtype = exercise.get('question_type', 'Unknown')
                        visuals_count = len(exercise.get('mentioned_visuals', []))
                        print(f"      ğŸ“ Q{exercise.get('original_question_number', '')}"
                              f"({exercise.get('sub_question_number', '')}): {qtype}, "
                              f"{visuals_count} visuals")
                    
                    all_exercises.extend(exercises)
                
                # Rate limiting to avoid API overload
                time.sleep(1)
                
            except Exception as e:
                print(f"  âŒ Error processing page {page_number}: {str(e)[:100]}...")
                continue
        
        print(f"\nğŸ“š EXTRACTION COMPLETED")
        print(f"ğŸ“ Total questions extracted: {len(all_exercises)}")
        
        # Print statistics
        # self._print_extraction_statistics(all_exercises)
        
        return all_exercises



    def _has_exercise_content(self, page_text):
        """
        Check if page contains actual exercise/practice sections (not just any questions)
        
        Args:
            page_text (str): Text content of the page
            
        Returns:
            bool: True if page has actual exercise section headers
        """
        import re
        
        # Strict exercise section patterns with numbers
        exercise_patterns = [
            r'àª¸à«àªµàª¾àª§à«àª¯àª¾àª¯\s+\d+\.\d+',      # àª¸à«àªµàª¾àª§à«àª¯àª¾àª¯ 3.1, àª¸à«àªµàª¾àª§à«àª¯àª¾àª¯ 2.5
            r'àª…àª­à«àª¯àª¾àª¸\s+\d+\.\d+',         # àª…àª­à«àª¯àª¾àª¸ 3.1
            r'àªªà«àª°à«‡àª•à«àªŸàª¿àª¸\s+\d+\.\d+',       # àªªà«àª°à«‡àª•à«àªŸàª¿àª¸ 3.1
            r'Exercise\s+\d+\.\d+',        # Exercise 3.1
            r'àª•àª¸à«‹àªŸà«€\s+\d+\.\d+'           # àª•àª¸à«‹àªŸà«€ 3.1
        ]
        
        # Check for specific exercise section headers
        for pattern in exercise_patterns:
            match = re.search(pattern, page_text)
            if match:
                found_section = match.group()
                print(f"    âœ… Found exercise section: {found_section}")
                return True
        
        # Secondary check for exercise indicators without numbers (less strict)
        basic_indicators = ['àª¸à«àªµàª¾àª§à«àª¯àª¾àª¯', 'àª…àª­à«àª¯àª¾àª¸', 'àªªà«àª°àª¶à«àª¨à«‹']
        
        for indicator in basic_indicators:
            if indicator in page_text:
                # Additional validation: check if followed by numbered questions
                if self._has_numbered_questions_after_indicator(page_text, indicator):
                    print(f"    âœ… Found exercise content with {indicator}")
                    return True
        
        print(f"    â­ï¸  No exercise section found on this page")
        return False

    def _has_numbered_questions_after_indicator(self, page_text, indicator):
        """
        Check if there are numbered questions after the exercise indicator
        
        Args:
            page_text (str): Text content of the page
            indicator (str): Exercise indicator like 'àª¸à«àªµàª¾àª§à«àª¯àª¾àª¯'
            
        Returns:
            bool: True if numbered questions found after indicator
        """
        import re
        
        # Find the position of the indicator
        indicator_pos = page_text.find(indicator)
        if indicator_pos == -1:
            return False
        
        # Look for numbered questions after the indicator
        text_after_indicator = page_text[indicator_pos:]
        
        # Patterns for numbered questions
        question_patterns = [
            r'\n\s*\d+\.\s+',          # 1. 2. 3.
            r'\n\s*\(\s*[ivx]+\s*\)',  # (i) (ii) (iii)
            r'\n\s*[àª…àª†àª‡]\)\s+'        # àª…) àª†) àª‡)
        ]
        
        for pattern in question_patterns:
            if re.search(pattern, text_after_indicator[:500]):  # Check next 500 chars
                return True
        
        return False





    def _extract_exercises_with_ai(self, page_text, chapter_name, page_number):
        """
        Use Gemini AI to extract and classify exercise questions from page text
        
        Args:
            page_text (str): Text content of the page
            chapter_name (str): Name of the mathematics chapter
            page_number (int): Page number for reference
            
        Returns:
            list: List of extracted exercise questions with full metadata
        """
        print(f"    ğŸ¤– Using AI to extract exercises from page {page_number}")
        

        prompt = f"""
        àª¤àª®à«‡ àª§à«‹àª°àª£ 10 àª—à«àªœàª°àª¾àª¤à«€ àª®àª¾àª§à«àª¯àª®àª¨àª¾ àª—àª£àª¿àª¤ àªªàª¾àª à«àª¯àªªà«àª¸à«àª¤àª•àª®àª¾àª‚àª¥à«€ **àª«àª•à«àª¤ àª¸à«àªµàª¾àª§à«àª¯àª¾àª¯/àª…àª­à«àª¯àª¾àª¸ àªµàª¿àª­àª¾àª—àª¨àª¾** àªªà«àª°àª¶à«àª¨à«‹ àª•àª¾àª¢à«€ àª°àª¹à«àª¯àª¾ àª›à«‹.

        **JSON àª†àª‰àªŸàªªà«àªŸ àª«àª°àªœàª¿àª¯àª¾àª¤ àª¨àª¿àª¯àª®à«‹:**
        - àª¤àª®àª¾àª°à«‹ àªœàªµàª¾àª¬ àª®àª¾àª¤à«àª° JSON format àª®àª¾àª‚ àª¹à«‹àªµà«‹ àªœà«‹àªˆàª
        - Explanation field àª®àª¾àª‚ line breaks (\\n) àª¨ àªµàª¾àªªàª°à«‹
        - Mathematical equations àª…àª¨à«‡ symbols àªµàª¾àªªàª°à«€ àª¶àª•à«‹ àª›à«‹ (x=3, y=2, +, -, =, etc.)
        - àª«àª•à«àª¤ new lines àª…àª¨à«‡ tabs àªŸàª¾àª³à«‹

        **àª®àª¹àª¤à«àªµàªªà«‚àª°à«àª£ àª¨àª¿àª¯àª®à«‹:**
        1. àª«àª•à«àª¤ "àª¸à«àªµàª¾àª§à«àª¯àª¾àª¯ X.Y" àª…àª¥àªµàª¾ "àª…àª­à«àª¯àª¾àª¸ X.Y" àª¹à«‡àª¡àª¿àª‚àª— àªªàª›à«€àª¨àª¾ àªªà«àª°àª¶à«àª¨à«‹ àªœ àª•àª¾àª¢à«‹
        2. àª¦àª°à«‡àª• àªªà«àª°àª¶à«àª¨ àª®àª¾àªŸà«‡ **àª«àª°àªœàª¿àª¯àª¾àª¤** àª¸àª‚àªªà«‚àª°à«àª£ àªœàªµàª¾àª¬ àª…àª¨à«‡ àª¸à«àªªàª·à«àªŸà«€àª•àª°àª£ àª†àªªà«‹
        3. Exercise number àªšà«‹àª•à«àª•àª¸ àª¶à«‹àª§à«€àª¨à«‡ àª¬àª¹àª¾àª° àª•àª¾àª¢à«‹
        4. **àª‰àªªàªªà«àª°àª¶à«àª¨ àª¬àª¨àª¾àªµàª¤à«€ àªµàª–àª¤à«‡ àª®à«àª–à«àª¯ àªªà«àª°àª¶à«àª¨àª¨à«‹ àª¸àª‚àª¦àª°à«àª­ àªœà«‹àª¡à«‹**

        **àª‰àªªàªªà«àª°àª¶à«àª¨ àª¨àª¿àª¯àª®à«‹ - àª…àª¤àª¿ àª®àª¹àª¤à«àªµàªªà«‚àª°à«àª£:**
        - àª®à«àª–à«àª¯ àªªà«àª°àª¶à«àª¨: "àª¨à«€àªšà«‡àª¨àª¾ àª¸àª®à«€àª•àª°àª£àª¯à«àª—à«àª® àª¹àª² àª•àª°à«‹:"
        - àª‰àªªàªªà«àª°àª¶à«àª¨ (i): "x + y = 5, x - y = 1" 
        - **àª¸àª‚àªªà«‚àª°à«àª£ àªªà«àª°àª¶à«àª¨ àª¬àª¨àª¾àªµà«‹**: "àª¨à«€àªšà«‡àª¨àª¾ àª¸àª®à«€àª•àª°àª£àª¯à«àª—à«àª® àª¹àª² àª•àª°à«‹: x + y = 5, x - y = 1"
        - **àª®àª¾àª¤à«àª° equations àªœ àª¨ àª²àª–à«‹** - àª¹àª‚àª®à«‡àª¶àª¾ àª®à«àª–à«àª¯ instruction àª¸àª¾àª¥à«‡ àªœà«‹àª¡à«‹

        **Answer àª«à«€àª²à«àª¡:**
        - àª®àª¾àª¤à«àª° àª…àª‚àª¤àª¿àª® àªªàª°àª¿àª£àª¾àª® àª²àª–à«‹ (àªœà«‡àª® àª•à«‡: "x = 3, y = 2")

        **Explanation àª«à«€àª²à«àª¡:**
        - àªªàª—àª²àª¾àªµàª¾àª° àª—àª¾àª£àª¿àª¤àª¿àª• àª‰àª•à«‡àª² àªàª• continuous text àª®àª¾àª‚ àª²àª–à«‹
        - Mathematical equations àª¸àª¾àªšàªµà«€ àª°àª¾àª–à«‹
        - àªªàª—àª²àª¾àª“ àªµàªšà«àªšà«‡ "àªªàª›à«€" àª…àª¥àªµàª¾ "àª…àª¨à«‡" àªµàª¾àªªàª°à«‹

        **9 àªªà«àª°àª¶à«àª¨ àªªà«àª°àª•àª¾àª°à«‹:**
        1. "Very Short / Objective (O)" - 1 àª—à«àª£
        2. "MCQs (Multiple Choice Questions)" 
        3. "True / False" 
        4. "Fill in the Blanks" 
        5. "Short Answer â€“ I (SA-I)" - 2 àª—à«àª£
        6. "Short Answer â€“ II (SA-II)" - 3 àª—à«àª£
        7. "Long Answer (LA)" - 4+ àª—à«àª£
        8. "Match the Values / (Jodka Jodo)" 
        9. "Diagram-Based"

        àªªàª¾àª¨àª¾àª¨à«àª‚ àª²àª–àª¾àª£:
        {page_text}

        **àª«àª•à«àª¤ àª¨à«€àªšà«‡àª¨àª¾ JSON àª«à«‹àª°à«àª®à«‡àªŸ àª®àª¾àª‚ àª†àªªà«‹:**
        [{{"exercise_number": "3.1", "page_number": {page_number}, "original_question_number": "1", "sub_question_number": "i", "question_text": "àª¨à«€àªšà«‡àª¨àª¾ àª¸àª®à«€àª•àª°àª£àª¯à«àª—à«àª® àª¹àª² àª•àª°à«‹: x + y = 5 àª…àª¨à«‡ x - y = 1", "question_type": "Short Answer â€“ II (SA-II)", "answer": "x = 3, y = 2", "explanation": "àª†àªªà«‡àª² x + y = 5 àª…àª¨à«‡ x - y = 1, àª¬àª‚àª¨à«‡ àª¸àª®à«€àª•àª°àª£ àª‰àª®à«‡àª°àª¤àª¾àª‚ 2x = 6 àª¤à«‡àª¥à«€ x = 3, àªªàª›à«€ x = 3 àªªà«àª°àª¥àª® àª¸àª®à«€àª•àª°àª£àª®àª¾àª‚ àª®à«‚àª•àª¤àª¾àª‚ 3 + y = 5 àª¤à«‡àª¥à«€ y = 2, àª† àª‰àª®à«‡àª°àªµàª¾àª¨à«€ àªªàª¦à«àª§àª¤àª¿ àª›à«‡.", "marks_estimate": 3, "difficulty": "Medium", "mentioned_visuals": []}}]

        **àªšà«‡àª¤àªµàª£à«€:**
        - Mathematical equations àªœàª¾àª³àªµà«€ àª°àª¾àª–à«‹
        - àª«àª•à«àª¤ line breaks àªŸàª¾àª³à«‹, equations àª¨àª¹à«€àª‚
        - àªœà«‹ àª•à«‹àªˆ àª¸à«àªµàª¾àª§à«àª¯àª¾àª¯ àªµàª¿àª­àª¾àª— àª¨ àª¹à«‹àª¯ àª¤à«‹ àª®àª¾àª¤à«àª° [] àª†àªªà«‹
        - **àª‰àªªàªªà«àª°àª¶à«àª¨à«‹ àª®àª¾àª‚ àª¹àª‚àª®à«‡àª¶àª¾ àª®à«àª–à«àª¯ instruction àª¶àª¾àª®à«‡àª² àª•àª°à«‹**
        """



        try:
            response = self.gemini_model.generate_content(prompt)
            self.api_calls["gemini_api"] += 1
            
            response_text = response.text.strip()
            
            if not response_text:
                return []
            
            # Clean markdown formatting if present
            response_text = self._clean_response_text(response_text)
            
        # Parse JSON response
            exercises = json.loads(response_text)
            
            if not isinstance(exercises, list):
                return []
            
            # Filter and validate exercises before adding metadata
            validated_exercises = []
            for exercise in exercises:
                if isinstance(exercise, dict):
                    exercise["chapter"] = chapter_name
                    exercise["extracted_at"] = datetime.now().isoformat()
                    exercise["source"] = "exercise"
                    exercise["status"] = "inactive"
                    validated_exercises.append(exercise)
                else:
                    print(f"      âš ï¸  Skipping invalid exercise type: {type(exercise)}")
            
            print(f"      âœ… Successfully extracted {len(validated_exercises)} exercises")
            return validated_exercises

            
        except json.JSONDecodeError as e:
            print(f"      âŒ JSON parsing error: {str(e)}")
            return []
        except Exception as e:
            print(f"      âŒ AI extraction error: {str(e)}")
            return []


    def _clean_response_text(self, response_text):
        """
        Clean markdown formatting from Gemini response
        
        Args:
            response_text (str): Raw response from Gemini
            
        Returns:
            str: Cleaned JSON text
        """
        # Remove markdown code blocks
        if response_text.startswith("```"):
            response_text = response_text.strip("`")
            if response_text.lower().startswith("json"):
                response_text = response_text[4:].strip()
        
        return response_text.strip()


    def _enhance_exercises_with_visual_content(self, exercises, page_data):
        """
        Enhance exercises with actual visual descriptions from page images
        
        Args:
            exercises (list): List of extracted exercises
            page_data (dict): Page data containing images
            
        Returns:
            list: Enhanced exercises with visual descriptions
        """
        page_images = page_data.get('images', [])
        if not page_images:
            return exercises
        
        print(f"      ğŸ–¼ï¸  Enhancing {len(exercises)} exercises with visual content")
        
        enhanced_exercises = []
        
        for exercise in exercises:
            # Add type checking to handle both dict and string cases
            if not isinstance(exercise, dict):
                print(f"        âš ï¸  Skipping invalid exercise type: {type(exercise)}")
                continue
            
            mentioned_visuals = exercise.get('mentioned_visuals', [])
            
            # Ensure mentioned_visuals is a list
            if not isinstance(mentioned_visuals, list):
                mentioned_visuals = []
                exercise['mentioned_visuals'] = mentioned_visuals
            
            for visual in mentioned_visuals:
                # Ensure visual is a dictionary
                if not isinstance(visual, dict):
                    continue
                    
                visual_ref = visual.get('reference', '')
                visual_type = visual.get('type', '')
                
                # Find matching description from page images
                matching_desc = self._find_matching_visual_description(
                    visual_ref, visual_type, page_images
                )
                
                if matching_desc:
                    visual['full_description'] = matching_desc
                    print(f"        âœ… Found description for {visual_ref}")
                else:
                    visual['full_description'] = "àªµàª°à«àª£àª¨ àª‰àªªàª²àª¬à«àª§ àª¨àª¥à«€"
                    print(f"        âš ï¸  No description found for {visual_ref}")
            
            enhanced_exercises.append(exercise)
        
        return enhanced_exercises




    def _find_matching_visual_description(self, visual_reference, visual_type, page_images):
        """
        Find matching image description based on reference and type
        
        Args:
            visual_reference (str): Reference like "àª†àª•à«ƒàª¤àª¿ 3.5"
            visual_type (str): Type like "àª†àª•à«ƒàª¤àª¿", "àª†àª²à«‡àª–"
            page_images (list): List of detected images on the page
            
        Returns:
            str or None: Matching description if found
        """
        import re
        
        # Method 1: Exact reference matching
        if visual_reference:
            ref_match = re.search(r'\d+\.\d+', visual_reference)
            if ref_match:
                ref_number = ref_match.group()
                ref_type = visual_reference.split()[0]  # àª†àª•à«ƒàª¤àª¿, àª†àª²à«‡àª–
                
                for image in page_images:
                    img_desc = image.get('educational_description', '')
                    if ref_number in img_desc and ref_type in img_desc:
                        return img_desc
        
        # Method 2: Type-based matching
        visual_type_lower = visual_type.lower()
        
        type_keywords = {
            'àª†àª•à«ƒàª¤àª¿': ['àª†àª•à«ƒàª¤àª¿', 'figure', 'diagram'],
            'àª†àª²à«‡àª–': ['àª†àª²à«‡àª–', 'graph', 'chart'],
            'àª•à«‹àª·à«àªŸàª•': ['àª•à«‹àª·à«àªŸàª•', 'table']
        }
        
        if visual_type_lower in type_keywords:
            keywords = type_keywords[visual_type_lower]
            
            for image in page_images:
                img_desc = image.get('educational_description', '').lower()
                if any(keyword in img_desc for keyword in keywords):
                    return image.get('educational_description', '')
        
        return None

    def _get_chapter_name(self, json_data):
        """
        Extract chapter name from JSON metadata
        
        Args:
            json_data (dict): Processed chapter JSON data
            
        Returns:
            str: Chapter name for context
        """
        # Try to get from chapter_info first
        chapter_summary = json_data.get('chapter_info', {}).get('chapter_summary', '')
        
        if chapter_summary:
            return chapter_summary.split('.')[0] if '.' in chapter_summary else chapter_summary[:50]
        
        # Fallback: extract from filename
        source_pdf = json_data.get('metadata', {}).get('source_pdf', '')
        return source_pdf.replace('.pdf', '').replace('-', ' ').title()

    def _print_extraction_statistics(self, exercises):
        """
        Print detailed statistics about extracted exercises
        
        Args:
            exercises (list): List of extracted exercises
        """
        if not exercises:
            return
            
        # Question type distribution
        question_types = {}
        difficulties = {}
        total_visuals = 0
        
        for exercise in exercises:
            # Count question types
            qtype = exercise.get('question_type', 'Unknown')
            question_types[qtype] = question_types.get(qtype, 0) + 1
            
            # Count difficulties
            difficulty = exercise.get('difficulty', 'Unknown')
            difficulties[difficulty] = difficulties.get(difficulty, 0) + 1
            
            # Count visual references
            total_visuals += len(exercise.get('mentioned_visuals', []))
        
        print(f"\nğŸ“Š EXTRACTION STATISTICS:")
        print(f"  ğŸ“ Total Questions: {len(exercises)}")
        print(f"  ğŸ–¼ï¸  Total Visual References: {total_visuals}")
        print(f"  ğŸ¤– AI API Calls: {self.api_calls['gemini_api']}")
        
        print(f"\nğŸ“‹ Question Type Distribution:")
        for qtype, count in sorted(question_types.items()):
            print(f"  ğŸ“„ {qtype}: {count}")
        
        print(f"\nğŸ¯ Difficulty Distribution:")
        for diff, count in sorted(difficulties.items()):
            print(f"  ğŸ”˜ {diff}: {count}")

    def save_exercises(self, exercises, output_file):
        """
        Save extracted exercises to JSON file with metadata
        
        Args:
            exercises (list): List of extracted exercises
            output_file (str): Output file path
        """
        print(f"\nğŸ’¾ Saving {len(exercises)} exercises to: {output_file}")
        
        # Create output data structure
        output_data = {
            "metadata": {
                "extraction_type": "exercises",
                "subject": "Mathematics",
                "total_questions": len(exercises),
                "extracted_at": datetime.now().isoformat(),
                "api_calls": self.api_calls["gemini_api"],
                "extractor_version": "1.0"
            },
            "exercises": exercises
        }
        
        # Write to file
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… EXERCISES SAVED SUCCESSFULLY")
        self._print_save_summary(exercises)

    def _print_save_summary(self, exercises):
        """
        Print summary of saved exercises
        
        Args:
            exercises (list): List of saved exercises
        """
        # Quick statistics for saved data
        exercise_numbers = set()
        unique_pages = set()
        
        for exercise in exercises:
            if exercise.get('exercise_number'):
                exercise_numbers.add(exercise['exercise_number'])
            if exercise.get('page_number'):
                unique_pages.add(exercise['page_number'])
        
        print(f"ğŸ“ˆ Save Summary:")
        print(f"  ğŸ“š Exercise Sets: {len(exercise_numbers)}")
        print(f"  ğŸ“„ Pages Processed: {len(unique_pages)}")
        print(f"  ğŸ’° Total API Cost: ~${self.api_calls['gemini_api'] * 0.01:.2f}")

def main():
    """Main execution function for the exercise extractor"""
    print("ğŸ“š GSEB Mathematics Exercise Extractor")
    print("ğŸ” Extract exercises from processed mathematics textbook JSON")
    print("ğŸ¯ Supports all mathematics chapters and topics")
    print("="*60)
    
    # Initialize extractor
    try:
        extractor = GSEBExerciseExtractor()
    except ValueError as e:
        print(f"âŒ Initialization Error: {str(e)}")
        return
    
    # Get input JSON file from user
    json_file = input("\nğŸ“‚ Enter path to processed JSON file: ").strip()
    if not os.path.exists(json_file):
        print("âŒ File not found!")
        return
    
    print(f"âœ… File found: {json_file}")
    
    # Load and process the chapter data
    try:
        print("\nğŸ”„ Loading chapter data...")
        json_data = extractor.load_processed_json(json_file)
        
        print("ğŸ”„ Starting exercise extraction...")
        exercises = extractor.extract_exercises_from_chapter(json_data)    
        
        if exercises:
            # Generate output filename with timestamp
            output_file = f"extracted_exercises_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            extractor.save_exercises(exercises, output_file)
            print(f"\nğŸ‰ SUCCESS! Exercises saved to: {output_file}")
        else:
            print("\nâš ï¸  No exercises found in the document")
            print("ğŸ’¡ Make sure the document contains àª¸à«àªµàª¾àª§à«àª¯àª¾àª¯/àª…àª­à«àª¯àª¾àª¸ sections")
            
    except Exception as e:
        print(f"âŒ Processing Error: {str(e)}")
        print("ğŸ’¡ Please check the JSON file format and try again")

if __name__ == "__main__":
    main()